"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[2631],{4351:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>d,frontMatter:()=>c,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"isaac-platform/perception-performance-benchmark","title":"Perception Pipeline Performance Benchmark Guide","description":"This document explains how to benchmark and validate that the perception pipeline processes data with latency under 500ms.","source":"@site/docs/isaac-platform/perception-performance-benchmark.md","sourceDirName":"isaac-platform","slug":"/isaac-platform/perception-performance-benchmark","permalink":"/./docs/isaac-platform/perception-performance-benchmark","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/isaac-platform/perception-performance-benchmark.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Goal Sending Interface for Navigation Testing","permalink":"/./docs/isaac-platform/goal-sending-interface"},"next":{"title":"NVIDIA Isaac Sim - Introduction","permalink":"/./docs/isaac-platform/isaac-sim-intro"}}');var s=r(4848),t=r(7074);const c={},o="Perception Pipeline Performance Benchmark Guide",a={},l=[{value:"Overview",id:"overview",level:2},{value:"Performance Requirements",id:"performance-requirements",level:2},{value:"Benchmarking Components",id:"benchmarking-components",level:2},{value:"1. Perception Benchmark Node",id:"1-perception-benchmark-node",level:3},{value:"2. Benchmark Test Scenarios",id:"2-benchmark-test-scenarios",level:3},{value:"3. Performance Metrics",id:"3-performance-metrics",level:3},{value:"Running Performance Benchmarks",id:"running-performance-benchmarks",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Steps",id:"steps",level:3},{value:"Benchmark Report",id:"benchmark-report",level:2},{value:"Expected Results",id:"expected-results",level:2},{value:"Troubleshooting Performance Issues",id:"troubleshooting-performance-issues",level:2},{value:"Integration with CI/CD",id:"integration-with-cicd",level:2}];function h(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"perception-pipeline-performance-benchmark-guide",children:"Perception Pipeline Performance Benchmark Guide"})}),"\n",(0,s.jsx)(n.p,{children:"This document explains how to benchmark and validate that the perception pipeline processes data with latency under 500ms."}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"The perception pipeline performance benchmarking system measures the time it takes for perception algorithms to process sensor data and generate meaningful outputs. This includes VSLAM, stereo processing, semantic segmentation, and other perception tasks."}),"\n",(0,s.jsx)(n.h2,{id:"performance-requirements",children:"Performance Requirements"}),"\n",(0,s.jsx)(n.p,{children:"The perception pipeline must meet the following performance targets:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Maximum latency"}),": 500ms end-to-end processing time"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Minimum throughput"}),": 2-10 Hz depending on the perception task"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"CPU utilization"}),": Under 80% on target hardware"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Memory usage"}),": Stable without leaks during extended operation"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"benchmarking-components",children:"Benchmarking Components"}),"\n",(0,s.jsx)(n.h3,{id:"1-perception-benchmark-node",children:"1. Perception Benchmark Node"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"File"}),": ",(0,s.jsx)(n.code,{children:"examples/perception_benchmark/perception_benchmark.py"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Purpose"}),": Measures processing time for perception pipeline components"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Features"}),":","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Timestamps input and output of perception nodes"}),"\n",(0,s.jsx)(n.li,{children:"Calculates end-to-end latency"}),"\n",(0,s.jsx)(n.li,{children:"Provides real-time performance statistics"}),"\n",(0,s.jsx)(n.li,{children:"Generates performance reports"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"2-benchmark-test-scenarios",children:"2. Benchmark Test Scenarios"}),"\n",(0,s.jsx)(n.p,{children:"Different perception tasks have different performance characteristics:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"VSLAM processing"}),": Visual-inertial odometry and mapping"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Stereo depth estimation"}),": Depth map generation from stereo cameras"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Semantic segmentation"}),": Pixel-level scene understanding"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Object detection"}),": Detection and classification of objects"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Feature extraction"}),": Key point and descriptor computation"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"3-performance-metrics",children:"3. Performance Metrics"}),"\n",(0,s.jsx)(n.p,{children:"Key metrics tracked during benchmarking:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Processing latency"}),": Time from input to processed output"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Frame rate"}),": Processing rate in Hz"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"CPU utilization"}),": Percentage of CPU used by perception nodes"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Memory usage"}),": RAM consumption during operation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"GPU utilization"}),": GPU usage for accelerated algorithms"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"running-performance-benchmarks",children:"Running Performance Benchmarks"}),"\n",(0,s.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"ROS 2 Humble with Isaac ROS perception packages"}),"\n",(0,s.jsx)(n.li,{children:"Benchmark test data or simulation environment"}),"\n",(0,s.jsx)(n.li,{children:"Performance monitoring tools (htop, nvidia-smi if applicable)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"steps",children:"Steps"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Set up the environment"}),":"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"source /opt/ros/humble/setup.bash\r\nsource ~/ros2_ws/install/setup.bash\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Run the benchmark script"}),":"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws/src/physical_ai_examples\r\npython3 perception_benchmark/perception_benchmark.py\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"3",children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Or use the launch file for integrated testing"}),":"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws/src/physical_ai_examples\r\nros2 launch perception_benchmark perception_benchmark.launch.py\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"4",children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Monitor performance in real-time"}),":","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Use provided visualization tools"}),"\n",(0,s.jsx)(n.li,{children:"Check console output for real-time statistics"}),"\n",(0,s.jsxs)(n.li,{children:["Monitor system resources with ",(0,s.jsx)(n.code,{children:"htop"})," or similar tools"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"benchmark-report",children:"Benchmark Report"}),"\n",(0,s.jsx)(n.p,{children:"The benchmark produces a comprehensive report including:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Average, minimum, and maximum processing latencies"}),"\n",(0,s.jsx)(n.li,{children:"Frame rates for different perception tasks"}),"\n",(0,s.jsx)(n.li,{children:"CPU and memory usage statistics"}),"\n",(0,s.jsx)(n.li,{children:"Whether the 500ms target was met"}),"\n",(0,s.jsx)(n.li,{children:"Performance bottlenecks identification"}),"\n",(0,s.jsx)(n.li,{children:"Recommendations for optimization"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"expected-results",children:"Expected Results"}),"\n",(0,s.jsx)(n.p,{children:"For the benchmark to pass:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Maximum latency must be < 500ms for all perception tasks"}),"\n",(0,s.jsx)(n.li,{children:"Average latency should be < 250ms for optimal performance"}),"\n",(0,s.jsx)(n.li,{children:"Frame rate should match or exceed sensor input rate"}),"\n",(0,s.jsx)(n.li,{children:"No significant performance degradation over time"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting-performance-issues",children:"Troubleshooting Performance Issues"}),"\n",(0,s.jsx)(n.p,{children:"If performance benchmarks fail to meet targets:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Profile perception nodes"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Use ROS 2 tools to identify bottlenecks"}),"\n",(0,s.jsx)(n.li,{children:"Check computational complexity of algorithms"}),"\n",(0,s.jsx)(n.li,{children:"Optimize critical code paths"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Hardware considerations"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Verify adequate CPU/GPU resources"}),"\n",(0,s.jsx)(n.li,{children:"Check memory bandwidth limitations"}),"\n",(0,s.jsx)(n.li,{children:"Consider hardware acceleration options"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Algorithm optimization"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Reduce image resolution if appropriate"}),"\n",(0,s.jsx)(n.li,{children:"Use approximate algorithms for faster processing"}),"\n",(0,s.jsx)(n.li,{children:"Implement multi-threading where possible"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"integration-with-cicd",children:"Integration with CI/CD"}),"\n",(0,s.jsx)(n.p,{children:"The benchmark script can be integrated into continuous integration workflows:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Example CI benchmark command\r\npython3 perception_benchmark/perception_benchmark.py\r\nif [ $? -eq 0 ]; then\r\n  echo "Performance benchmark passed"\r\nelse\r\n  echo "Performance benchmark failed - optimize perception pipeline"\r\n  exit 1\r\nfi\n'})})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},7074:(e,n,r)=>{r.d(n,{R:()=>c,x:()=>o});var i=r(6540);const s={},t=i.createContext(s);function c(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:c(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);