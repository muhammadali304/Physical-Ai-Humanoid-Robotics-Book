"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[9842],{3527:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"capstone/autonomous-humanoid","title":"Autonomous Humanoid - Capstone Project","description":"Learning Objectives","source":"@site/docs/capstone/autonomous-humanoid.md","sourceDirName":"capstone","slug":"/capstone/autonomous-humanoid","permalink":"/docs/capstone/autonomous-humanoid","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/capstone/autonomous-humanoid.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Capstone Project Integration Guide","permalink":"/docs/capstone/capstone-project-integration-guide"},"next":{"title":"Troubleshooting Guide - Physical AI & Humanoid Robotics","permalink":"/docs/appendix/troubleshooting"}}');var a=t(4848),o=t(7074);const s={sidebar_position:1},r="Autonomous Humanoid - Capstone Project",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Conceptual Overview",id:"conceptual-overview",level:2},{value:"Capstone System Architecture",id:"capstone-system-architecture",level:3},{value:"Key Capstone Components",id:"key-capstone-components",level:3},{value:"Project Scope",id:"project-scope",level:3},{value:"Hands-On Implementation",id:"hands-on-implementation",level:2},{value:"Setting Up the Capstone Package",id:"setting-up-the-capstone-package",level:3},{value:"Creating the Complete Humanoid URDF",id:"creating-the-complete-humanoid-urdf",level:3},{value:"Creating the Main Capstone Node",id:"creating-the-main-capstone-node",level:3},{value:"Creating a Capstone Launch File",id:"creating-a-capstone-launch-file",level:3},{value:"Creating a Capstone Demo Script",id:"creating-a-capstone-demo-script",level:3},{value:"Creating the Package Files",id:"creating-the-package-files",level:3},{value:"Testing &amp; Verification",id:"testing--verification",level:2},{value:"Running the Capstone System",id:"running-the-capstone-system",level:3},{value:"Useful Capstone Commands",id:"useful-capstone-commands",level:3},{value:"Performance Testing",id:"performance-testing",level:3},{value:"Common Issues",id:"common-issues",level:2},{value:"Issue: Joint trajectory controller not responding",id:"issue-joint-trajectory-controller-not-responding",level:3},{value:"Issue: Balance control instability",id:"issue-balance-control-instability",level:3},{value:"Issue: Integration conflicts between subsystems",id:"issue-integration-conflicts-between-subsystems",level:3},{value:"Issue: Computational overload with all systems active",id:"issue-computational-overload-with-all-systems-active",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Next Steps",id:"next-steps",level:2}];function m(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"autonomous-humanoid---capstone-project",children:"Autonomous Humanoid - Capstone Project"})}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Integrate all concepts learned throughout the book into a complete humanoid robot system"}),"\n",(0,a.jsx)(e.li,{children:"Implement a full autonomous humanoid robot with perception, planning, and action capabilities"}),"\n",(0,a.jsx)(e.li,{children:"Design and build a complex robotic system that combines all previous chapters"}),"\n",(0,a.jsx)(e.li,{children:"Create a complete deployment pipeline from simulation to real hardware"}),"\n",(0,a.jsx)(e.li,{children:"Implement advanced safety and recovery mechanisms"}),"\n",(0,a.jsx)(e.li,{children:"Demonstrate the complete physical AI and humanoid robotics system"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsx)(e.p,{children:"Before starting this capstone project, you should:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Have completed all previous chapters in this book"}),"\n",(0,a.jsx)(e.li,{children:"Mastered ROS 2 fundamentals, simulation, Isaac integration, and VLA systems"}),"\n",(0,a.jsx)(e.li,{children:"Have access to appropriate hardware (simulated or physical humanoid robot)"}),"\n",(0,a.jsx)(e.li,{children:"Understanding of all concepts from previous chapters"}),"\n",(0,a.jsx)(e.li,{children:"Experience with system integration and testing"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"conceptual-overview",children:"Conceptual Overview"}),"\n",(0,a.jsxs)(e.p,{children:["The ",(0,a.jsx)(e.strong,{children:"Autonomous Humanoid Capstone Project"})," represents the culmination of all concepts covered in this book. It integrates:"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"ROS 2 Fundamentals"}),": Nodes, topics, services, actions, and packages"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Simulation"}),": Gazebo and Unity for development and testing"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Isaac Platform"}),": Perception, navigation, and AI capabilities"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Vision-Language-Action"}),": Natural interaction and cognitive planning"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Hardware Integration"}),": Real-world deployment considerations"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"capstone-system-architecture",children:"Capstone System Architecture"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:"[USER INPUT] \u2192 [VOICE RECOGNITION] \u2192 [LLM PLANNING] \u2192 [PERCEPTION] \u2192 [NAVIGATION] \u2192 [CONTROL] \u2192 [ROBOT]\n     \u2191                  \u2193                \u2193            \u2191            \u2191            \u2191          \u2193\n[NATURAL LANGUAGE] \u2190 [TASK DECOMPOSITION] \u2190 [ENVIRONMENT MODEL] \u2190 [PATH PLANNING] \u2190 [MOTION CONTROL] \u2190 [SENSORS]\n"})}),"\n",(0,a.jsx)(e.h3,{id:"key-capstone-components",children:"Key Capstone Components"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Humanoid Robot Model"}),": Complete URDF model with multiple DOF joints"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Perception System"}),": Vision, LIDAR, IMU, and other sensor integration"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Cognitive Planning"}),": LLM-based high-level task planning"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Navigation System"}),": Autonomous movement and path planning"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Control System"}),": Low-level motor control and balance"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Safety System"}),": Emergency stops, collision avoidance, and error recovery"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"User Interface"}),": Voice commands and natural interaction"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"project-scope",children:"Project Scope"}),"\n",(0,a.jsx)(e.p,{children:"The capstone project involves creating a complete autonomous humanoid robot system that can:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Understand natural language commands"}),"\n",(0,a.jsx)(e.li,{children:"Perceive and navigate in its environment"}),"\n",(0,a.jsx)(e.li,{children:"Execute complex multi-step tasks"}),"\n",(0,a.jsx)(e.li,{children:"Adapt to changing conditions"}),"\n",(0,a.jsx)(e.li,{children:"Interact naturally with humans"}),"\n",(0,a.jsx)(e.li,{children:"Operate safely in real-world environments"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"hands-on-implementation",children:"Hands-On Implementation"}),"\n",(0,a.jsx)(e.h3,{id:"setting-up-the-capstone-package",children:"Setting Up the Capstone Package"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Create the capstone package\ncd ~/ros2_ws/src\nros2 pkg create --build-type ament_python capstone_humanoid\n"})}),"\n",(0,a.jsx)(e.h3,{id:"creating-the-complete-humanoid-urdf",children:"Creating the Complete Humanoid URDF"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Create capstone_humanoid/urdf/humanoid_robot.urdf.xacro:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<robot xmlns:xacro="http://www.ros.org/wiki/xacro" name="humanoid_robot">\n\n  \x3c!-- Constants --\x3e\n  <xacro:property name="M_PI" value="3.1415926535897931" />\n  <xacro:property name="torso_mass" value="10.0" />\n  <xacro:property name="head_mass" value="2.0" />\n  <xacro:property name="arm_mass" value="1.5" />\n  <xacro:property name="leg_mass" value="3.0" />\n  <xacro:property name="foot_mass" value="1.0" />\n\n  \x3c!-- Materials --\x3e\n  <material name="black">\n    <color rgba="0 0 0 1"/>\n  </material>\n  <material name="blue">\n    <color rgba="0 0 1 1"/>\n  </material>\n  <material name="green">\n    <color rgba="0 1 0 1"/>\n  </material>\n  <material name="grey">\n    <color rgba="0.5 0.5 0.5 1"/>\n  </material>\n  <material name="orange">\n    <color rgba="${255/255} ${108/255} ${10/255} 1"/>\n  </material>\n  <material name="brown">\n    <color rgba="${222/255} ${207/255} ${195/255} 1"/>\n  </material>\n  <material name="red">\n    <color rgba="0.8 0 0 1"/>\n  </material>\n  <material name="white">\n    <color rgba="1 1 1 1"/>\n  </material>\n\n  \x3c!-- Base Link --\x3e\n  <link name="base_link">\n    <inertial>\n      <mass value="1.0"/>\n      <inertia ixx="0.01" ixy="0.0" ixz="0.0" iyy="0.01" iyz="0.0" izz="0.01"/>\n    </inertial>\n    <visual>\n      <geometry>\n        <box size="0.1 0.1 0.1"/>\n      </geometry>\n      <material name="white"/>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="0.1 0.1 0.1"/>\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Torso --\x3e\n  <joint name="torso_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="torso_link"/>\n    <origin xyz="0 0 0.5" rpy="0 0 0"/>\n  </joint>\n\n  <link name="torso_link">\n    <inertial>\n      <mass value="${torso_mass}"/>\n      <origin xyz="0 0 0.3"/>\n      <inertia ixx="0.5" ixy="0.0" ixz="0.0" iyy="0.5" iyz="0.0" izz="0.2"/>\n    </inertial>\n    <visual>\n      <origin xyz="0 0 0.3"/>\n      <geometry>\n        <capsule radius="0.15" length="0.4"/>\n      </geometry>\n      <material name="grey"/>\n    </visual>\n    <collision>\n      <origin xyz="0 0 0.3"/>\n      <geometry>\n        <capsule radius="0.15" length="0.4"/>\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Head --\x3e\n  <joint name="neck_joint" type="revolute">\n    <parent link="torso_link"/>\n    <child link="head_link"/>\n    <origin xyz="0 0 0.7" rpy="0 0 0"/>\n    <axis xyz="0 1 0"/>\n    <limit lower="${-M_PI/4}" upper="${M_PI/4}" effort="100" velocity="1.0"/>\n  </joint>\n\n  <link name="head_link">\n    <inertial>\n      <mass value="${head_mass}"/>\n      <origin xyz="0 0 0.1"/>\n      <inertia ixx="0.05" ixy="0.0" ixz="0.0" iyy="0.05" iyz="0.0" izz="0.05"/>\n    </inertial>\n    <visual>\n      <origin xyz="0 0 0.1"/>\n      <geometry>\n        <sphere radius="0.15"/>\n      </geometry>\n      <material name="skin_color"/>\n    </visual>\n    <collision>\n      <origin xyz="0 0 0.1"/>\n      <geometry>\n        <sphere radius="0.15"/>\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Camera for head --\x3e\n  <joint name="camera_joint" type="fixed">\n    <parent link="head_link"/>\n    <child link="camera_link"/>\n    <origin xyz="0.05 0 0.1" rpy="0 0 0"/>\n  </joint>\n\n  <link name="camera_link">\n    <inertial>\n      <mass value="0.1"/>\n      <inertia ixx="0.001" ixy="0.0" ixz="0.0" iyy="0.001" iyz="0.0" izz="0.001"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Left Arm --\x3e\n  <joint name="left_shoulder_pitch" type="revolute">\n    <parent link="torso_link"/>\n    <child link="left_upper_arm"/>\n    <origin xyz="0.2 0.15 0.5" rpy="0 0 0"/>\n    <axis xyz="1 0 0"/>\n    <limit lower="${-M_PI/2}" upper="${M_PI/2}" effort="50" velocity="2.0"/>\n  </joint>\n\n  <link name="left_upper_arm">\n    <inertial>\n      <mass value="${arm_mass}"/>\n      <origin xyz="0 0 -0.15"/>\n      <inertia ixx="0.05" ixy="0.0" ixz="0.0" iyy="0.05" iyz="0.0" izz="0.01"/>\n    </inertial>\n    <visual>\n      <origin xyz="0 0 -0.15"/>\n      <geometry>\n        <capsule radius="0.05" length="0.25"/>\n      </geometry>\n      <material name="grey"/>\n    </visual>\n    <collision>\n      <origin xyz="0 0 -0.15"/>\n      <geometry>\n        <capsule radius="0.05" length="0.25"/>\n      </geometry>\n    </collision>\n  </link>\n\n  <joint name="left_elbow" type="revolute">\n    <parent link="left_upper_arm"/>\n    <child link="left_forearm"/>\n    <origin xyz="0 0 -0.3" rpy="0 0 0"/>\n    <axis xyz="0 1 0"/>\n    <limit lower="${-M_PI/2}" upper="${M_PI/2}" effort="30" velocity="2.0"/>\n  </joint>\n\n  <link name="left_forearm">\n    <inertial>\n      <mass value="${arm_mass*0.7}"/>\n      <origin xyz="0 0 -0.1"/>\n      <inertia ixx="0.02" ixy="0.0" ixz="0.0" iyy="0.02" iyz="0.0" izz="0.005"/>\n    </inertial>\n    <visual>\n      <origin xyz="0 0 -0.1"/>\n      <geometry>\n        <capsule radius="0.04" length="0.15"/>\n      </geometry>\n      <material name="grey"/>\n    </visual>\n    <collision>\n      <origin xyz="0 0 -0.1"/>\n      <geometry>\n        <capsule radius="0.04" length="0.15"/>\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Right Arm (mirror of left) --\x3e\n  <joint name="right_shoulder_pitch" type="revolute">\n    <parent link="torso_link"/>\n    <child link="right_upper_arm"/>\n    <origin xyz="0.2 -0.15 0.5" rpy="0 0 0"/>\n    <axis xyz="1 0 0"/>\n    <limit lower="${-M_PI/2}" upper="${M_PI/2}" effort="50" velocity="2.0"/>\n  </joint>\n\n  <link name="right_upper_arm">\n    <inertial>\n      <mass value="${arm_mass}"/>\n      <origin xyz="0 0 -0.15"/>\n      <inertia ixx="0.05" ixy="0.0" ixz="0.0" iyy="0.05" iyz="0.0" izz="0.01"/>\n    </inertial>\n    <visual>\n      <origin xyz="0 0 -0.15"/>\n      <geometry>\n        <capsule radius="0.05" length="0.25"/>\n      </geometry>\n      <material name="grey"/>\n    </visual>\n    <collision>\n      <origin xyz="0 0 -0.15"/>\n      <geometry>\n        <capsule radius="0.05" length="0.25"/>\n      </geometry>\n    </collision>\n  </link>\n\n  <joint name="right_elbow" type="revolute">\n    <parent link="right_upper_arm"/>\n    <child link="right_forearm"/>\n    <origin xyz="0 0 -0.3" rpy="0 0 0"/>\n    <axis xyz="0 1 0"/>\n    <limit lower="${-M_PI/2}" upper="${M_PI/2}" effort="30" velocity="2.0"/>\n  </joint>\n\n  <link name="right_forearm">\n    <inertial>\n      <mass value="${arm_mass*0.7}"/>\n      <origin xyz="0 0 -0.1"/>\n      <inertia ixx="0.02" ixy="0.0" ixz="0.0" iyy="0.02" iyz="0.0" izz="0.005"/>\n    </inertial>\n    <visual>\n      <origin xyz="0 0 -0.1"/>\n      <geometry>\n        <capsule radius="0.04" length="0.15"/>\n      </geometry>\n      <material name="grey"/>\n    </visual>\n    <collision>\n      <origin xyz="0 0 -0.1"/>\n      <geometry>\n        <capsule radius="0.04" length="0.15"/>\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Left Leg --\x3e\n  <joint name="left_hip_pitch" type="revolute">\n    <parent link="torso_link"/>\n    <child link="left_thigh"/>\n    <origin xyz="-0.1 0.1 0.1" rpy="0 0 0"/>\n    <axis xyz="1 0 0"/>\n    <limit lower="${-M_PI/2}" upper="${M_PI/4}" effort="100" velocity="1.0"/>\n  </joint>\n\n  <link name="left_thigh">\n    <inertial>\n      <mass value="${leg_mass}"/>\n      <origin xyz="0 0 -0.25"/>\n      <inertia ixx="0.1" ixy="0.0" ixz="0.0" iyy="0.1" iyz="0.0" izz="0.02"/>\n    </inertial>\n    <visual>\n      <origin xyz="0 0 -0.25"/>\n      <geometry>\n        <capsule radius="0.08" length="0.4"/>\n      </geometry>\n      <material name="grey"/>\n    </visual>\n    <collision>\n      <origin xyz="0 0 -0.25"/>\n      <geometry>\n        <capsule radius="0.08" length="0.4"/>\n      </geometry>\n    </collision>\n  </link>\n\n  <joint name="left_knee" type="revolute">\n    <parent link="left_thigh"/>\n    <child link="left_shin"/>\n    <origin xyz="0 0 -0.5" rpy="0 0 0"/>\n    <axis xyz="1 0 0"/>\n    <limit lower="${-M_PI/2}" upper="${M_PI/4}" effort="80" velocity="1.0"/>\n  </joint>\n\n  <link name="left_shin">\n    <inertial>\n      <mass value="${leg_mass*0.8}"/>\n      <origin xyz="0 0 -0.25"/>\n      <inertia ixx="0.08" ixy="0.0" ixz="0.0" iyy="0.08" iyz="0.0" izz="0.015"/>\n    </inertial>\n    <visual>\n      <origin xyz="0 0 -0.25"/>\n      <geometry>\n        <capsule radius="0.07" length="0.4"/>\n      </geometry>\n      <material name="grey"/>\n    </visual>\n    <collision>\n      <origin xyz="0 0 -0.25"/>\n      <geometry>\n        <capsule radius="0.07" length="0.4"/>\n      </geometry>\n    </collision>\n  </link>\n\n  <joint name="left_ankle" type="revolute">\n    <parent link="left_shin"/>\n    <child link="left_foot"/>\n    <origin xyz="0 0 -0.5" rpy="0 0 0"/>\n    <axis xyz="0 1 0"/>\n    <limit lower="${-M_PI/6}" upper="${M_PI/6}" effort="50" velocity="1.0"/>\n  </joint>\n\n  <link name="left_foot">\n    <inertial>\n      <mass value="${foot_mass}"/>\n      <origin xyz="0.05 0 -0.05"/>\n      <inertia ixx="0.01" ixy="0.0" ixz="0.0" iyy="0.01" iyz="0.0" izz="0.01"/>\n    </inertial>\n    <visual>\n      <origin xyz="0.05 0 -0.05"/>\n      <geometry>\n        <box size="0.2 0.1 0.1"/>\n      </geometry>\n      <material name="black"/>\n    </visual>\n    <collision>\n      <origin xyz="0.05 0 -0.05"/>\n      <geometry>\n        <box size="0.2 0.1 0.1"/>\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Right Leg (mirror of left) --\x3e\n  <joint name="right_hip_pitch" type="revolute">\n    <parent link="torso_link"/>\n    <child link="right_thigh"/>\n    <origin xyz="-0.1 -0.1 0.1" rpy="0 0 0"/>\n    <axis xyz="1 0 0"/>\n    <limit lower="${-M_PI/2}" upper="${M_PI/4}" effort="100" velocity="1.0"/>\n  </joint>\n\n  <link name="right_thigh">\n    <inertial>\n      <mass value="${leg_mass}"/>\n      <origin xyz="0 0 -0.25"/>\n      <inertia ixx="0.1" ixy="0.0" ixz="0.0" iyy="0.1" iyz="0.0" izz="0.02"/>\n    </inertial>\n    <visual>\n      <origin xyz="0 0 -0.25"/>\n      <geometry>\n        <capsule radius="0.08" length="0.4"/>\n      </geometry>\n      <material name="grey"/>\n    </visual>\n    <collision>\n      <origin xyz="0 0 -0.25"/>\n      <geometry>\n        <capsule radius="0.08" length="0.4"/>\n      </geometry>\n    </collision>\n  </link>\n\n  <joint name="right_knee" type="revolute">\n    <parent link="right_thigh"/>\n    <child link="right_shin"/>\n    <origin xyz="0 0 -0.5" rpy="0 0 0"/>\n    <axis xyz="1 0 0"/>\n    <limit lower="${-M_PI/2}" upper="${M_PI/4}" effort="80" velocity="1.0"/>\n  </joint>\n\n  <link name="right_shin">\n    <inertial>\n      <mass value="${leg_mass*0.8}"/>\n      <origin xyz="0 0 -0.25"/>\n      <inertia ixx="0.08" ixy="0.0" ixz="0.0" iyy="0.08" iyz="0.0" izz="0.015"/>\n    </inertial>\n    <visual>\n      <origin xyz="0 0 -0.25"/>\n      <geometry>\n        <capsule radius="0.07" length="0.4"/>\n      </geometry>\n      <material name="grey"/>\n    </visual>\n    <collision>\n      <origin xyz="0 0 -0.25"/>\n      <geometry>\n        <capsule radius="0.07" length="0.4"/>\n      </geometry>\n    </collision>\n  </link>\n\n  <joint name="right_ankle" type="revolute">\n    <parent link="right_shin"/>\n    <child link="right_foot"/>\n    <origin xyz="0 0 -0.5" rpy="0 0 0"/>\n    <axis xyz="0 1 0"/>\n    <limit lower="${-M_PI/6}" upper="${M_PI/6}" effort="50" velocity="1.0"/>\n  </joint>\n\n  <link name="right_foot">\n    <inertial>\n      <mass value="${foot_mass}"/>\n      <origin xyz="0.05 0 -0.05"/>\n      <inertia ixx="0.01" ixy="0.0" ixz="0.0" iyy="0.01" iyz="0.0" izz="0.01"/>\n    </inertial>\n    <visual>\n      <origin xyz="0.05 0 -0.05"/>\n      <geometry>\n        <box size="0.2 0.1 0.1"/>\n      </geometry>\n      <material name="black"/>\n    </visual>\n    <collision>\n      <origin xyz="0.05 0 -0.05"/>\n      <geometry>\n        <box size="0.2 0.1 0.1"/>\n      </geometry>\n    </collision>\n  </link>\n\n  \x3c!-- Gazebo plugins for the robot --\x3e\n  <gazebo>\n    <plugin name="gazebo_ros_control" filename="libgazebo_ros_control.so">\n      <robotNamespace>/humanoid_robot</robotNamespace>\n    </plugin>\n  </gazebo>\n\n  \x3c!-- Camera sensor --\x3e\n  <gazebo reference="camera_link">\n    <sensor type="camera" name="camera_sensor">\n      <update_rate>30.0</update_rate>\n      <camera name="head">\n        <horizontal_fov>1.3962634</horizontal_fov>\n        <image>\n          <width>800</width>\n          <height>600</height>\n          <format>R8G8B8</format>\n        </image>\n        <clip>\n          <near>0.02</near>\n          <far>300</far>\n        </clip>\n      </camera>\n      <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n        <alwaysOn>true</alwaysOn>\n        <updateRate>30.0</updateRate>\n        <cameraName>humanoid_robot/camera</cameraName>\n        <imageTopicName>image_raw</imageTopicName>\n        <cameraInfoTopicName>camera_info</cameraInfoTopicName>\n        <frameName>camera_link</frameName>\n        <hackBaseline>0.07</hackBaseline>\n        <distortionK1>0.0</distortionK1>\n        <distortionK2>0.0</distortionK2>\n        <distortionK3>0.0</distortionK3>\n        <distortionT1>0.0</distortionT1>\n        <distortionT2>0.0</distortionT2>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n  \x3c!-- IMU sensor --\x3e\n  <gazebo reference="torso_link">\n    <sensor type="imu" name="imu_sensor">\n      <always_on>true</always_on>\n      <update_rate>100</update_rate>\n      <imu>\n        <angular_velocity>\n          <x>\n            <noise type="gaussian">\n              <mean>0.0</mean>\n              <stddev>2e-4</stddev>\n            </noise>\n          </x>\n          <y>\n            <noise type="gaussian">\n              <mean>0.0</mean>\n              <stddev>2e-4</stddev>\n            </noise>\n          </y>\n          <z>\n            <noise type="gaussian">\n              <mean>0.0</mean>\n              <stddev>2e-4</stddev>\n            </noise>\n          </z>\n        </angular_velocity>\n        <linear_acceleration>\n          <x>\n            <noise type="gaussian">\n              <mean>0.0</mean>\n              <stddev>1.7e-2</stddev>\n            </noise>\n          </x>\n          <y>\n            <noise type="gaussian">\n              <mean>0.0</mean>\n              <stddev>1.7e-2</stddev>\n            </noise>\n          </y>\n          <z>\n            <noise type="gaussian">\n              <mean>0.0</mean>\n              <stddev>1.7e-2</stddev>\n            </noise>\n          </z>\n        </linear_acceleration>\n      </imu>\n      <plugin filename="libgazebo_ros_imu_sensor.so" name="imu_plugin">\n        <topicName>imu</topicName>\n        <bodyName>torso_link</bodyName>\n        <updateRateHZ>100.0</updateRateHZ>\n        <gaussianNoise>0.0</gaussianNoise>\n        <frameName>torso_link</frameName>\n        <initialOrientationAsReference>false</initialOrientationAsReference>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n</robot>\n'})}),"\n",(0,a.jsx)(e.h3,{id:"creating-the-main-capstone-node",children:"Creating the Main Capstone Node"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\n\n\"\"\"\nMain capstone node for the autonomous humanoid robot system.\n\"\"\"\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import Image, Imu, JointState\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom nav_msgs.msg import Odometry\nfrom builtin_interfaces.msg import Duration\nfrom trajectory_msgs.msg import JointTrajectory, JointTrajectoryPoint\nfrom control_msgs.msg import JointTrajectoryControllerState\nimport threading\nimport time\nimport json\nfrom typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass HumanoidState:\n    \"\"\"Current state of the humanoid robot.\"\"\"\n    joint_angles: Dict[str, float] = None\n    imu_data: Dict[str, float] = None\n    vision_data: Any = None\n    position: Dict[str, float] = None\n    velocity: Dict[str, float] = None\n    balance_state: str = \"stable\"\n    battery_level: float = 100.0\n    timestamp: float = 0.0\n\n\nclass CapstoneHumanoidNode(Node):\n    \"\"\"\n    Main node for the autonomous humanoid robot system.\n    Integrates all components learned throughout the book.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('capstone_humanoid_node')\n\n        # Initialize humanoid state\n        self.state = HumanoidState()\n        self.state_lock = threading.Lock()\n\n        # Initialize subsystems\n        self.voice_system = VoiceCommandSystem(self)\n        self.planning_system = PlanningSystem(self)\n        self.perception_system = PerceptionSystem(self)\n        self.navigation_system = NavigationSystem(self)\n        self.control_system = ControlSystem(self)\n        self.safety_system = SafetySystem(self)\n\n        # Create subscribers for all sensors\n        self.joint_state_sub = self.create_subscription(\n            JointState,\n            '/joint_states',\n            self.joint_state_callback,\n            10\n        )\n\n        self.imu_sub = self.create_subscription(\n            Imu,\n            '/imu',\n            self.imu_callback,\n            10\n        )\n\n        self.image_sub = self.create_subscription(\n            Image,\n            '/camera/image_raw',\n            self.image_callback,\n            10\n        )\n\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            '/odom',\n            self.odom_callback,\n            10\n        )\n\n        # Subscribe to command inputs\n        self.voice_command_sub = self.create_subscription(\n            String,\n            '/voice_commands',\n            self.voice_command_callback,\n            10\n        )\n\n        self.text_command_sub = self.create_subscription(\n            String,\n            '/text_commands',\n            self.text_command_callback,\n            10\n        )\n\n        # Create publishers\n        self.status_pub = self.create_publisher(String, '/humanoid_status', 10)\n        self.joint_cmd_pub = self.create_publisher(JointTrajectory, '/joint_trajectory_controller/joint_trajectory', 10)\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n        self.goal_pub = self.create_publisher(PoseStamped, '/goal_pose', 10)\n\n        # Timer for main control loop\n        self.main_timer = self.create_timer(0.05, self.main_control_loop)  # 20Hz\n\n        # Initialize systems\n        self.initialize_systems()\n\n        self.get_logger().info('Capstone humanoid robot system initialized')\n\n    def initialize_systems(self):\n        \"\"\"Initialize all subsystems.\"\"\"\n        self.voice_system.initialize()\n        self.planning_system.initialize()\n        self.perception_system.initialize()\n        self.navigation_system.initialize()\n        self.control_system.initialize()\n        self.safety_system.initialize()\n\n        self.get_logger().info('All subsystems initialized')\n\n    def joint_state_callback(self, msg):\n        \"\"\"Handle joint state updates.\"\"\"\n        with self.state_lock:\n            self.state.joint_angles = dict(zip(msg.name, msg.position))\n            self.state.velocity = dict(zip(msg.name, msg.velocity))\n            self.state.timestamp = time.time()\n\n    def imu_callback(self, msg):\n        \"\"\"Handle IMU updates.\"\"\"\n        with self.state_lock:\n            self.state.imu_data = {\n                'orientation': [msg.orientation.x, msg.orientation.y, msg.orientation.z, msg.orientation.w],\n                'angular_velocity': [msg.angular_velocity.x, msg.angular_velocity.y, msg.angular_velocity.z],\n                'linear_acceleration': [msg.linear_acceleration.x, msg.linear_acceleration.y, msg.linear_acceleration.z]\n            }\n            self.state.balance_state = self.assess_balance(self.state.imu_data)\n            self.state.timestamp = time.time()\n\n    def image_callback(self, msg):\n        \"\"\"Handle camera image updates.\"\"\"\n        with self.state_lock:\n            self.state.vision_data = msg\n            self.state.timestamp = time.time()\n\n    def odom_callback(self, msg):\n        \"\"\"Handle odometry updates.\"\"\"\n        with self.state_lock:\n            self.state.position = {\n                'x': msg.pose.pose.position.x,\n                'y': msg.pose.pose.position.y,\n                'z': msg.pose.pose.position.z\n            }\n            self.state.timestamp = time.time()\n\n    def voice_command_callback(self, msg):\n        \"\"\"Handle voice command input.\"\"\"\n        command = msg.data\n        self.get_logger().info(f'Received voice command: {command}')\n\n        # Process through the integrated system\n        self.process_command(command)\n\n    def text_command_callback(self, msg):\n        \"\"\"Handle text command input.\"\"\"\n        command = msg.data\n        self.get_logger().info(f'Received text command: {command}')\n\n        # Process through the integrated system\n        self.process_command(command)\n\n    def process_command(self, command: str):\n        \"\"\"Process command through the integrated system.\"\"\"\n        # Step 1: Parse command with voice system\n        parsed_command = self.voice_system.parse_command(command)\n\n        # Step 2: Plan with LLM system\n        plan = self.planning_system.generate_plan(parsed_command)\n\n        if plan:\n            # Step 3: Execute with control system\n            success = self.control_system.execute_plan(plan)\n\n            if success:\n                self.get_logger().info('Command executed successfully')\n            else:\n                self.get_logger().error('Command execution failed')\n        else:\n            self.get_logger().error('Could not generate plan for command')\n\n    def assess_balance(self, imu_data: Dict) -> str:\n        \"\"\"Assess robot balance based on IMU data.\"\"\"\n        # Simple balance assessment based on orientation\n        orientation = imu_data['orientation']\n        # Calculate tilt angles from quaternion\n        w, x, y, z = orientation\n\n        # Simplified balance check (in practice, this would be more sophisticated)\n        roll = math.atan2(2*(w*x + y*z), 1 - 2*(x*x + y*y))\n        pitch = math.asin(2*(w*y - z*x))\n\n        if abs(roll) > 0.5 or abs(pitch) > 0.5:  # 0.5 rad \u2248 28.6 degrees\n            return \"unstable\"\n        else:\n            return \"stable\"\n\n    def main_control_loop(self):\n        \"\"\"Main control loop for the humanoid robot.\"\"\"\n        with self.state_lock:\n            current_state = self.state\n\n        # Safety checks\n        safety_ok = self.safety_system.check_safety(current_state)\n        if not safety_ok:\n            self.emergency_stop()\n            return\n\n        # Balance maintenance\n        if current_state.balance_state == \"unstable\":\n            self.maintain_balance()\n\n        # Publish system status\n        self.publish_status()\n\n        # Process any pending tasks\n        self.process_pending_tasks()\n\n    def maintain_balance(self):\n        \"\"\"Maintain robot balance.\"\"\"\n        self.get_logger().warn('Balance instability detected - taking corrective action')\n\n        # Send balance correction commands\n        # In practice, this would use inverse kinematics and balance control algorithms\n        balance_cmd = JointTrajectory()\n        balance_cmd.joint_names = ['left_ankle', 'right_ankle', 'left_hip_pitch', 'right_hip_pitch']\n\n        point = JointTrajectoryPoint()\n        point.positions = [0.0, 0.0, 0.0, 0.0]  # Return to neutral position\n        point.time_from_start = Duration(sec=0, nanosec=100000000)  # 0.1 seconds\n\n        balance_cmd.points.append(point)\n        self.joint_cmd_pub.publish(balance_cmd)\n\n    def emergency_stop(self):\n        \"\"\"Emergency stop procedure.\"\"\"\n        self.get_logger().fatal('EMERGENCY STOP ACTIVATED')\n\n        # Stop all motion\n        stop_twist = Twist()\n        self.cmd_vel_pub.publish(stop_twist)\n\n        # Set all joints to safe position\n        safe_cmd = JointTrajectory()\n        safe_cmd.joint_names = list(self.state.joint_angles.keys()) if self.state.joint_angles else []\n\n        if safe_cmd.joint_names:\n            point = JointTrajectoryPoint()\n            # Set all joints to 0 or safe position\n            point.positions = [0.0] * len(safe_cmd.joint_names)\n            point.time_from_start = Duration(sec=0, nanosec=100000000)  # 0.1 seconds\n            safe_cmd.points.append(point)\n            self.joint_cmd_pub.publish(safe_cmd)\n\n    def publish_status(self):\n        \"\"\"Publish humanoid system status.\"\"\"\n        status_msg = String()\n        with self.state_lock:\n            status_data = {\n                'balance_state': self.state.balance_state,\n                'battery_level': self.state.battery_level,\n                'position': self.state.position,\n                'joint_angles': self.state.joint_angles,\n                'timestamp': time.time()\n            }\n            status_msg.data = json.dumps(status_data)\n\n        self.status_pub.publish(status_msg)\n\n    def process_pending_tasks(self):\n        \"\"\"Process any pending tasks.\"\"\"\n        # In a real implementation, this would manage task queues\n        pass\n\n\nclass VoiceCommandSystem:\n    \"\"\"Handles voice command processing.\"\"\"\n\n    def __init__(self, parent_node):\n        self.parent_node = parent_node\n\n    def initialize(self):\n        \"\"\"Initialize voice command system.\"\"\"\n        self.parent_node.get_logger().info('Voice command system initialized')\n\n    def parse_command(self, command: str) -> Dict:\n        \"\"\"Parse voice command.\"\"\"\n        # In practice, this would use more sophisticated NLP\n        return {\n            'original': command,\n            'intent': self.extract_intent(command),\n            'entities': self.extract_entities(command),\n            'confidence': 0.9\n        }\n\n    def extract_intent(self, command: str) -> str:\n        \"\"\"Extract intent from command.\"\"\"\n        command_lower = command.lower()\n        if 'move' in command_lower or 'go' in command_lower:\n            return 'navigation'\n        elif 'pick' in command_lower or 'grasp' in command_lower:\n            return 'manipulation'\n        elif 'dance' in command_lower or 'wave' in command_lower:\n            return 'gesture'\n        else:\n            return 'other'\n\n    def extract_entities(self, command: str) -> Dict:\n        \"\"\"Extract entities from command.\"\"\"\n        entities = {}\n        command_lower = command.lower()\n\n        # Extract locations\n        locations = ['kitchen', 'bedroom', 'living room', 'office']\n        for loc in locations:\n            if loc in command_lower:\n                entities['location'] = loc\n                break\n\n        # Extract objects\n        objects = ['ball', 'cup', 'book', 'toy']\n        for obj in objects:\n            if obj in command_lower:\n                entities['object'] = obj\n                break\n\n        return entities\n\n\nclass PlanningSystem:\n    \"\"\"Handles high-level planning using LLMs.\"\"\"\n\n    def __init__(self, parent_node):\n        self.parent_node = parent_node\n\n    def initialize(self):\n        \"\"\"Initialize planning system.\"\"\"\n        self.parent_node.get_logger().info('Planning system initialized')\n\n    def generate_plan(self, parsed_command: Dict) -> Optional[List[Dict]]:\n        \"\"\"Generate plan based on parsed command.\"\"\"\n        intent = parsed_command['intent']\n        entities = parsed_command['entities']\n\n        if intent == 'navigation':\n            return self.generate_navigation_plan(entities)\n        elif intent == 'manipulation':\n            return self.generate_manipulation_plan(entities)\n        elif intent == 'gesture':\n            return self.generate_gesture_plan(entities)\n        else:\n            return self.generate_generic_plan(parsed_command)\n\n    def generate_navigation_plan(self, entities: Dict) -> List[Dict]:\n        \"\"\"Generate navigation plan.\"\"\"\n        plan = []\n\n        # Navigate to location if specified\n        if 'location' in entities:\n            plan.append({\n                'action': 'navigate_to',\n                'parameters': {'location': entities['location']},\n                'description': f'Navigate to {entities[\"location\"]}'\n            })\n        else:\n            # Default navigation action\n            plan.append({\n                'action': 'move_forward',\n                'parameters': {'distance': 1.0, 'speed': 0.5},\n                'description': 'Move forward 1 meter'\n            })\n\n        return plan\n\n    def generate_manipulation_plan(self, entities: Dict) -> List[Dict]:\n        \"\"\"Generate manipulation plan.\"\"\"\n        plan = []\n\n        if 'object' in entities:\n            plan.extend([\n                {\n                    'action': 'locate_object',\n                    'parameters': {'object_type': entities['object']},\n                    'description': f'Locate {entities[\"object\"]}'\n                },\n                {\n                    'action': 'approach_object',\n                    'parameters': {'object_type': entities['object']},\n                    'description': f'Approach {entities[\"object\"]}'\n                },\n                {\n                    'action': 'grasp_object',\n                    'parameters': {'object_type': entities['object']},\n                    'description': f'Grasp {entities[\"object\"]}'\n                }\n            ])\n\n        return plan\n\n    def generate_gesture_plan(self, entities: Dict) -> List[Dict]:\n        \"\"\"Generate gesture plan.\"\"\"\n        plan = []\n\n        original_cmd = entities.get('original', '').lower()\n\n        if 'wave' in original_cmd:\n            plan.extend([\n                {\n                    'action': 'raise_arm',\n                    'parameters': {'arm': 'right', 'angle': 0.5},\n                    'description': 'Raise right arm to wave position'\n                },\n                {\n                    'action': 'wave_hand',\n                    'parameters': {'repetitions': 3},\n                    'description': 'Wave hand 3 times'\n                },\n                {\n                    'action': 'lower_arm',\n                    'parameters': {'arm': 'right'},\n                    'description': 'Lower right arm'\n                }\n            ])\n        elif 'dance' in original_cmd:\n            plan.extend([\n                {\n                    'action': 'move_legs',\n                    'parameters': {'pattern': 'stepping', 'duration': 5.0},\n                    'description': 'Perform stepping dance for 5 seconds'\n                },\n                {\n                    'action': 'move_arms',\n                    'parameters': {'pattern': 'swinging', 'duration': 5.0},\n                    'description': 'Swing arms for 5 seconds'\n                }\n            ])\n\n        return plan\n\n    def generate_generic_plan(self, parsed_command: Dict) -> List[Dict]:\n        \"\"\"Generate generic plan.\"\"\"\n        return [{\n            'action': 'acknowledge',\n            'parameters': {'message': parsed_command['original']},\n            'description': f'Acknowledge command: {parsed_command[\"original\"]}'\n        }]\n\n\nclass PerceptionSystem:\n    \"\"\"Handles perception and environmental awareness.\"\"\"\n\n    def __init__(self, parent_node):\n        self.parent_node = parent_node\n\n    def initialize(self):\n        \"\"\"Initialize perception system.\"\"\"\n        self.parent_node.get_logger().info('Perception system initialized')\n\n    def process_vision_data(self, image_data):\n        \"\"\"Process camera image data.\"\"\"\n        # In practice, this would use computer vision algorithms\n        pass\n\n    def update_environment_model(self):\n        \"\"\"Update environment model based on sensor data.\"\"\"\n        # Integrate data from all sensors to build environment model\n        pass\n\n\nclass NavigationSystem:\n    \"\"\"Handles navigation and path planning.\"\"\"\n\n    def __init__(self, parent_node):\n        self.parent_node = parent_node\n\n    def initialize(self):\n        \"\"\"Initialize navigation system.\"\"\"\n        self.parent_node.get_logger().info('Navigation system initialized')\n\n    def navigate_to(self, location: str):\n        \"\"\"Navigate to specified location.\"\"\"\n        # In practice, this would interface with navigation stack\n        pass\n\n\nclass ControlSystem:\n    \"\"\"Handles low-level control and actuation.\"\"\"\n\n    def __init__(self, parent_node):\n        self.parent_node = parent_node\n\n    def initialize(self):\n        \"\"\"Initialize control system.\"\"\"\n        self.parent_node.get_logger().info('Control system initialized')\n\n    def execute_plan(self, plan: List[Dict]) -> bool:\n        \"\"\"Execute a plan.\"\"\"\n        success = True\n        for step in plan:\n            if not self.execute_step(step):\n                success = False\n                break\n        return success\n\n    def execute_step(self, step: Dict) -> bool:\n        \"\"\"Execute a single step.\"\"\"\n        action = step['action']\n        params = step['parameters']\n\n        self.parent_node.get_logger().info(f'Executing action: {action}')\n\n        try:\n            if action == 'navigate_to':\n                return self.execute_navigation(params)\n            elif action == 'move_forward':\n                return self.execute_move_forward(params)\n            elif action == 'raise_arm':\n                return self.execute_raise_arm(params)\n            elif action == 'wave_hand':\n                return self.execute_wave_hand(params)\n            elif action == 'move_legs':\n                return self.execute_move_legs(params)\n            elif action == 'acknowledge':\n                return self.execute_acknowledge(params)\n            else:\n                self.parent_node.get_logger().warn(f'Unknown action: {action}')\n                return False\n\n        except Exception as e:\n            self.parent_node.get_logger().error(f'Error executing action {action}: {e}')\n            return False\n\n    def execute_navigation(self, params: Dict) -> bool:\n        \"\"\"Execute navigation action.\"\"\"\n        location = params.get('location', 'unknown')\n        self.parent_node.get_logger().info(f'Navigating to {location}')\n        # In practice, this would send navigation goals\n        time.sleep(2)  # Simulate navigation time\n        return True\n\n    def execute_move_forward(self, params: Dict) -> bool:\n        \"\"\"Execute forward movement.\"\"\"\n        distance = params.get('distance', 1.0)\n        speed = params.get('speed', 0.5)\n\n        # Create and publish velocity command\n        twist = Twist()\n        twist.linear.x = speed\n        self.parent_node.cmd_vel_pub.publish(twist)\n\n        # Simulate movement\n        time.sleep(distance / speed)\n\n        # Stop the robot\n        stop_twist = Twist()\n        self.parent_node.cmd_vel_pub.publish(stop_twist)\n\n        return True\n\n    def execute_raise_arm(self, params: Dict) -> bool:\n        \"\"\"Execute arm raising action.\"\"\"\n        arm = params.get('arm', 'left')\n        angle = params.get('angle', 0.5)\n\n        # Create joint trajectory command\n        traj = JointTrajectory()\n        if arm == 'right':\n            traj.joint_names = ['right_shoulder_pitch', 'right_elbow']\n        else:\n            traj.joint_names = ['left_shoulder_pitch', 'left_elbow']\n\n        point = JointTrajectoryPoint()\n        if arm == 'right':\n            point.positions = [angle, 0.2]  # Raise and slightly bend elbow\n        else:\n            point.positions = [angle, 0.2]\n        point.time_from_start = Duration(sec=1, nanosec=0)  # 1 second\n\n        traj.points.append(point)\n        self.parent_node.joint_cmd_pub.publish(traj)\n\n        time.sleep(1.5)  # Allow time for movement\n        return True\n\n    def execute_wave_hand(self, params: Dict) -> bool:\n        \"\"\"Execute waving action.\"\"\"\n        repetitions = params.get('repetitions', 3)\n\n        for i in range(repetitions):\n            # Wave motion: alternate elbow angles\n            traj = JointTrajectory()\n            traj.joint_names = ['right_elbow']\n\n            point1 = JointTrajectoryPoint()\n            point1.positions = [0.5]  # Elbow bent\n            point1.time_from_start = Duration(sec=0, nanosec=200000000)  # 0.2 seconds\n            traj.points.append(point1)\n\n            point2 = JointTrajectoryPoint()\n            point2.positions = [-0.5]  # Elbow bent other way\n            point2.time_from_start = Duration(sec=0, nanosec=400000000)  # 0.4 seconds\n            traj.points.append(point2)\n\n            self.parent_node.joint_cmd_pub.publish(traj)\n            time.sleep(0.4)\n\n        return True\n\n    def execute_move_legs(self, params: Dict) -> bool:\n        \"\"\"Execute leg movement.\"\"\"\n        duration = params.get('duration', 5.0)\n\n        # Simple stepping motion\n        start_time = time.time()\n        while time.time() - start_time < duration:\n            # Alternate hip and knee movements\n            traj = JointTrajectory()\n            traj.joint_names = ['left_hip_pitch', 'right_hip_pitch', 'left_knee', 'right_knee']\n\n            point = JointTrajectoryPoint()\n            # Create alternating stepping pattern\n            t = time.time() - start_time\n            left_hip = math.sin(t * 2) * 0.2  # Oscillate hip\n            right_hip = math.sin(t * 2 + math.pi) * 0.2  # Opposite phase\n            point.positions = [left_hip, right_hip, 0.0, 0.0]\n            point.time_from_start = Duration(sec=0, nanosec=100000000)  # 0.1 seconds\n\n            traj.points.append(point)\n            self.parent_node.joint_cmd_pub.publish(traj)\n            time.sleep(0.1)\n\n        return True\n\n    def execute_acknowledge(self, params: Dict) -> bool:\n        \"\"\"Execute acknowledgment action.\"\"\"\n        message = params.get('message', 'acknowledged')\n        self.parent_node.get_logger().info(f'Acknowledged: {message}')\n        return True\n\n\nclass SafetySystem:\n    \"\"\"Handles safety monitoring and emergency procedures.\"\"\"\n\n    def __init__(self, parent_node):\n        self.parent_node = parent_node\n\n    def initialize(self):\n        \"\"\"Initialize safety system.\"\"\"\n        self.parent_node.get_logger().info('Safety system initialized')\n\n    def check_safety(self, state: HumanoidState) -> bool:\n        \"\"\"Check if system is in safe state.\"\"\"\n        # Check balance\n        if state.balance_state == \"unstable\":\n            self.parent_node.get_logger().warn('Balance safety violation')\n            return False\n\n        # Check joint limits (simplified)\n        if state.joint_angles:\n            for joint, angle in state.joint_angles.items():\n                # Check if joint is at extreme position (simplified check)\n                if abs(angle) > 2.0:  # Beyond safe range\n                    self.parent_node.get_logger().warn(f'Joint {joint} at unsafe position: {angle}')\n                    return False\n\n        # Check battery level\n        if state.battery_level < 10.0:  # Below 10%\n            self.parent_node.get_logger().warn(f'Low battery: {state.battery_level}%')\n            # Could return False if battery critically low, or just warn\n\n        return True\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = CapstoneHumanoidNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info('Capstone humanoid node stopped by user')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(e.h3,{id:"creating-a-capstone-launch-file",children:"Creating a Capstone Launch File"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Create launch/capstone_humanoid_launch.py:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription, TimerAction\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\nfrom launch_ros.actions import Node\nfrom launch_ros.substitutions import FindPackageShare\nimport os\n\n\ndef generate_launch_description():\n    # Declare launch arguments\n    use_sim_time = DeclareLaunchArgument(\n        'use_sim_time',\n        default_value='true',\n        description='Use simulation time if true'\n    )\n\n    robot_model = DeclareLaunchArgument(\n        'robot_model',\n        default_value='humanoid',\n        description='Robot model to use'\n    )\n\n    # Robot state publisher\n    robot_state_publisher = Node(\n        package='robot_state_publisher',\n        executable='robot_state_publisher',\n        name='robot_state_publisher',\n        parameters=[\n            {'use_sim_time': LaunchConfiguration('use_sim_time')},\n            {'robot_description': PathJoinSubstitution([\n                FindPackageShare('capstone_humanoid'),\n                'urdf',\n                'humanoid_robot.urdf.xacro'\n            ])}\n        ]\n    )\n\n    # Joint state publisher\n    joint_state_publisher = Node(\n        package='joint_state_publisher',\n        executable='joint_state_publisher',\n        name='joint_state_publisher',\n        parameters=[\n            {'use_sim_time': LaunchConfiguration('use_sim_time')}\n        ]\n    )\n\n    # Gazebo simulation\n    gazebo = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource([\n            PathJoinSubstitution([\n                FindPackageShare('gazebo_ros'),\n                'launch',\n                'gazebo.launch.py'\n            ])\n        ]),\n        launch_arguments={\n            'verbose': 'false',\n            'pause': 'false',\n        }.items()\n    )\n\n    # Spawn robot in Gazebo\n    spawn_entity = Node(\n        package='gazebo_ros',\n        executable='spawn_entity.py',\n        arguments=[\n            '-topic', 'robot_description',\n            '-entity', 'humanoid_robot',\n            '-x', '0', '-y', '0', '-z', '1.0'  # Start 1m above ground\n        ],\n        output='screen'\n    )\n\n    # Main capstone node\n    capstone_humanoid_node = Node(\n        package='capstone_humanoid',\n        executable='capstone_humanoid_node',\n        name='capstone_humanoid_node',\n        parameters=[\n            {'use_sim_time': LaunchConfiguration('use_sim_time')}\n        ],\n        output='screen'\n    )\n\n    # Isaac ROS perception nodes (if available)\n    # This would include depth estimation, object detection, etc.\n    # For brevity, we'll define them conceptually\n\n    # Isaac navigation (if available)\n    # This would include visual SLAM, path planning, etc.\n\n    # Return the launch description\n    return LaunchDescription([\n        use_sim_time,\n        robot_model,\n        robot_state_publisher,\n        joint_state_publisher,\n        gazebo,\n        TimerAction(\n            period=3.0,\n            actions=[spawn_entity]\n        ),\n        TimerAction(\n            period=5.0,\n            actions=[capstone_humanoid_node]\n        )\n    ])\n"})}),"\n",(0,a.jsx)(e.h3,{id:"creating-a-capstone-demo-script",children:"Creating a Capstone Demo Script"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Create scripts/capstone_demo.py:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\n"""\nCapstone demonstration script for autonomous humanoid robot.\n"""\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Twist\nimport time\n\n\nclass CapstoneDemoNode(Node):\n    """\n    Node to demonstrate the capstone humanoid robot capabilities.\n    """\n\n    def __init__(self):\n        super().__init__(\'capstone_demo_node\')\n\n        # Create publishers for different command types\n        self.voice_cmd_pub = self.create_publisher(String, \'/voice_commands\', 10)\n        self.text_cmd_pub = self.create_publisher(String, \'/text_commands\', 10)\n\n        self.get_logger().info(\'Capstone demo node initialized\')\n\n    def run_demo(self):\n        """Run the complete demo sequence."""\n        self.get_logger().info(\'Starting capstone demo sequence...\')\n\n        # Demo sequence\n        demo_commands = [\n            ("Hello robot", "Initial greeting"),\n            ("Move forward 2 meters", "Navigation demonstration"),\n            ("Wave your hand", "Gesture demonstration"),\n            ("Turn left", "Rotation demonstration"),\n            ("Dance for 10 seconds", "Complex movement demonstration"),\n            ("Go to the kitchen", "Advanced navigation"),\n            ("Stop", "Emergency stop demonstration")\n        ]\n\n        for command, description in demo_commands:\n            self.get_logger().info(f\'Demo: {description}\')\n            self.get_logger().info(f\'Command: "{command}"\')\n\n            # Send command\n            cmd_msg = String()\n            cmd_msg.data = command\n            self.voice_cmd_pub.publish(cmd_msg)\n\n            # Wait for execution\n            time.sleep(5)  # Wait 5 seconds between commands\n\n        self.get_logger().info(\'Capstone demo sequence completed\')\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    demo_node = CapstoneDemoNode()\n\n    try:\n        demo_node.run_demo()\n    except KeyboardInterrupt:\n        demo_node.get_logger().info(\'Demo interrupted by user\')\n    finally:\n        demo_node.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,a.jsx)(e.h3,{id:"creating-the-package-files",children:"Creating the Package Files"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Update package.xml:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>\n<package format="3">\n  <name>capstone_humanoid</name>\n  <version>0.0.1</version>\n  <description>Capstone project for autonomous humanoid robot</description>\n  <maintainer email="user@todo.todo">user</maintainer>\n  <license>Apache-2.0</license>\n\n  <depend>rclpy</depend>\n  <depend>std_msgs</depend>\n  <depend>geometry_msgs</depend>\n  <depend>sensor_msgs</depend>\n  <depend>nav_msgs</depend>\n  <depend>trajectory_msgs</depend>\n  <depend>control_msgs</depend>\n  <depend>builtin_interfaces</depend>\n  <depend>robot_state_publisher</depend>\n  <depend>joint_state_publisher</depend>\n\n  <export>\n    <build_type>ament_python</build_type>\n  </export>\n</package>\n'})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Create setup.py:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"from setuptools import find_packages, setup\n\npackage_name = 'capstone_humanoid'\n\nsetup(\n    name=package_name,\n    version='0.0.1',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n        ('share/' + package_name + '/urdf', ['urdf/humanoid_robot.urdf.xacro']),\n        ('share/' + package_name + '/launch', ['launch/capstone_humanoid_launch.py']),\n        ('share/' + package_name + '/scripts', ['scripts/capstone_demo.py']),\n    ],\n    install_requires=['setuptools'],\n    zip_safe=True,\n    maintainer='user',\n    maintainer_email='user@todo.todo',\n    description='Capstone project for autonomous humanoid robot',\n    license='Apache-2.0',\n    tests_require=['pytest'],\n    entry_points={\n        'console_scripts': [\n            'capstone_humanoid_node = capstone_humanoid.capstone_humanoid_node:main',\n            'capstone_demo = capstone_humanoid.scripts.capstone_demo:main',\n        ],\n    },\n)\n"})}),"\n",(0,a.jsx)(e.h2,{id:"testing--verification",children:"Testing & Verification"}),"\n",(0,a.jsx)(e.h3,{id:"running-the-capstone-system",children:"Running the Capstone System"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.strong,{children:"Build the capstone package:"})}),"\n"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"cd ~/ros2_ws\ncolcon build --packages-select capstone_humanoid\nsource install/setup.bash\n"})}),"\n",(0,a.jsxs)(e.ol,{start:"2",children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.strong,{children:"Run the complete capstone system:"})}),"\n"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Terminal 1: Launch the robot simulation\nros2 launch capstone_humanoid capstone_humanoid_launch.py\n\n# Terminal 2: Run the capstone node\nros2 run capstone_humanoid capstone_humanoid_node\n\n# Terminal 3: Send commands\nros2 topic pub /voice_commands std_msgs/msg/String \"data: 'Hello robot'\"\n\n# Terminal 4: Monitor status\nros2 topic echo /humanoid_status\n"})}),"\n",(0,a.jsxs)(e.ol,{start:"3",children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.strong,{children:"Run the demo sequence:"})}),"\n"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"ros2 run capstone_humanoid capstone_demo\n"})}),"\n",(0,a.jsx)(e.h3,{id:"useful-capstone-commands",children:"Useful Capstone Commands"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.strong,{children:"Monitor all capstone topics:"})}),"\n"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# System status\nros2 topic echo /humanoid_status\n\n# Joint states\nros2 topic echo /joint_states\n\n# Camera feed\nros2 run image_view image_view image:=/humanoid_robot/camera/image_raw\n\n# IMU data\nros2 topic echo /imu\n"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.strong,{children:"Send various commands:"})}),"\n"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Navigation commands\nros2 topic pub /voice_commands std_msgs/msg/String \"data: 'Move forward 2 meters'\"\nros2 topic pub /voice_commands std_msgs/msg/String \"data: 'Go to the kitchen'\"\n\n# Gesture commands\nros2 topic pub /voice_commands std_msgs/msg/String \"data: 'Wave your hand'\"\nros2 topic pub /voice_commands std_msgs/msg/String \"data: 'Dance for 10 seconds'\"\n\n# Emergency commands\nros2 topic pub /voice_commands std_msgs/msg/String \"data: 'Stop'\"\nros2 topic pub /voice_commands std_msgs/msg/String \"data: 'Emergency halt'\"\n"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.strong,{children:"Visualize in RViz:"})}),"\n"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# For robot state visualization\nrviz2\n# Add RobotModel, TF, and other displays\n"})}),"\n",(0,a.jsx)(e.h3,{id:"performance-testing",children:"Performance Testing"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Test system response time to commands\n# Test coordination between all subsystems\n# Test safety system responses\n# Test battery life simulation\n# Test long-term operation stability\n"})}),"\n",(0,a.jsx)(e.h2,{id:"common-issues",children:"Common Issues"}),"\n",(0,a.jsx)(e.h3,{id:"issue-joint-trajectory-controller-not-responding",children:"Issue: Joint trajectory controller not responding"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Solution"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Verify controller configuration in Gazebo"}),"\n",(0,a.jsx)(e.li,{children:"Check that joint names match between URDF and controller"}),"\n",(0,a.jsx)(e.li,{children:"Ensure proper controller manager setup"}),"\n",(0,a.jsx)(e.li,{children:"Verify ROS 2 control packages are installed"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"issue-balance-control-instability",children:"Issue: Balance control instability"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Solution"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Implement proper PID controllers for balance"}),"\n",(0,a.jsx)(e.li,{children:"Use IMU feedback for real-time adjustments"}),"\n",(0,a.jsx)(e.li,{children:"Implement fall detection and recovery"}),"\n",(0,a.jsx)(e.li,{children:"Use center of mass calculations"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"issue-integration-conflicts-between-subsystems",children:"Issue: Integration conflicts between subsystems"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Solution"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Implement proper state management"}),"\n",(0,a.jsx)(e.li,{children:"Use message passing for coordination"}),"\n",(0,a.jsx)(e.li,{children:"Implement priority-based arbitration"}),"\n",(0,a.jsx)(e.li,{children:"Create clear interfaces between subsystems"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"issue-computational-overload-with-all-systems-active",children:"Issue: Computational overload with all systems active"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Solution"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Optimize each subsystem individually"}),"\n",(0,a.jsx)(e.li,{children:"Use multi-threading where appropriate"}),"\n",(0,a.jsx)(e.li,{children:"Implement selective processing based on priority"}),"\n",(0,a.jsx)(e.li,{children:"Use efficient algorithms and data structures"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"The capstone project integrates all concepts learned throughout the book"}),"\n",(0,a.jsx)(e.li,{children:"Successful humanoid robots require careful coordination of multiple subsystems"}),"\n",(0,a.jsx)(e.li,{children:"Safety systems are paramount in humanoid robotics"}),"\n",(0,a.jsx)(e.li,{children:"Real-time performance is critical for stable operation"}),"\n",(0,a.jsx)(e.li,{children:"Simulation is essential for safe development and testing"}),"\n",(0,a.jsx)(e.li,{children:"Modularity and clear interfaces enable maintainable code"}),"\n",(0,a.jsx)(e.li,{children:"Comprehensive testing ensures system reliability"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsx)(e.p,{children:"In the next chapters, you'll learn about hardware selection, deployment strategies, and troubleshooting techniques for real-world humanoid robot deployments."})]})}function d(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(m,{...n})}):m(n)}},7074:(n,e,t)=>{t.d(e,{R:()=>s,x:()=>r});var i=t(6540);const a={},o=i.createContext(a);function s(n){const e=i.useContext(o);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:s(n.components),i.createElement(o.Provider,{value:e},n.children)}}}]);