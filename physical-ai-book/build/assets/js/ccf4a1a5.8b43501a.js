"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[7547],{4720:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>r,contentTitle:()=>o,default:()=>d,frontMatter:()=>l,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"vla/llm-planning","title":"LLM Planning - Cognitive Planning with Large Language Models","description":"Learning Objectives","source":"@site/docs/vla/llm-planning.md","sourceDirName":"vla","slug":"/vla/llm-planning","permalink":"/docs/vla/llm-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/vla/llm-planning.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"VLA Integration - Vision-Language-Action Systems","permalink":"/docs/vla/integration"},"next":{"title":"Voice Commands - Natural Language Interaction with Robots","permalink":"/docs/vla/voice-commands"}}');var s=a(4848),i=a(7074);const l={sidebar_position:2},o="LLM Planning - Cognitive Planning with Large Language Models",r={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Conceptual Overview",id:"conceptual-overview",level:2},{value:"Key Capabilities of LLMs in Robotics",id:"key-capabilities-of-llms-in-robotics",level:3},{value:"LLM Integration Architecture",id:"llm-integration-architecture",level:3},{value:"Advantages of LLM-Based Planning",id:"advantages-of-llm-based-planning",level:3},{value:"Hands-On Implementation",id:"hands-on-implementation",level:2},{value:"Installing LLM Dependencies",id:"installing-llm-dependencies",level:3},{value:"Creating an LLM Planning Node",id:"creating-an-llm-planning-node",level:3},{value:"Creating a Plan Execution Node",id:"creating-a-plan-execution-node",level:3},{value:"Creating a Task Manager Node",id:"creating-a-task-manager-node",level:3},{value:"Creating a Local LLM Integration (Alternative to API-based)",id:"creating-a-local-llm-integration-alternative-to-api-based",level:3},{value:"Creating a Safety and Validation Node",id:"creating-a-safety-and-validation-node",level:3},{value:"Creating a Complete LLM Planning Package",id:"creating-a-complete-llm-planning-package",level:3},{value:"Creating a Launch File",id:"creating-a-launch-file",level:3},{value:"Testing &amp; Verification",id:"testing--verification",level:2},{value:"Running LLM Planning System",id:"running-llm-planning-system",level:3},{value:"Useful LLM Planning Commands",id:"useful-llm-planning-commands",level:3},{value:"Performance Testing",id:"performance-testing",level:3},{value:"Common Issues",id:"common-issues",level:2},{value:"Issue: API rate limits or costs with remote LLMs",id:"issue-api-rate-limits-or-costs-with-remote-llms",level:3},{value:"Issue: Hallucinations or incorrect plans from LLM",id:"issue-hallucinations-or-incorrect-plans-from-llm",level:3},{value:"Issue: Latency in plan generation",id:"issue-latency-in-plan-generation",level:3},{value:"Issue: Safety and validation challenges",id:"issue-safety-and-validation-challenges",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Next Steps",id:"next-steps",level:2}];function p(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"llm-planning---cognitive-planning-with-large-language-models",children:"LLM Planning - Cognitive Planning with Large Language Models"})}),"\n",(0,s.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Understand how Large Language Models (LLMs) can be integrated with robotic planning"}),"\n",(0,s.jsx)(e.li,{children:"Implement cognitive planning systems using LLMs for high-level reasoning"}),"\n",(0,s.jsx)(e.li,{children:"Create natural language interfaces for robot task specification"}),"\n",(0,s.jsx)(e.li,{children:"Design prompting strategies for effective robot planning"}),"\n",(0,s.jsx)(e.li,{children:"Integrate LLM-based planning with low-level robot control"}),"\n",(0,s.jsx)(e.li,{children:"Evaluate and validate LLM-generated plans for safety and feasibility"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsx)(e.p,{children:"Before starting this chapter, you should:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Have ROS 2 Humble Hawksbill installed and configured"}),"\n",(0,s.jsx)(e.li,{children:"Understand ROS 2 nodes, services, and action interfaces"}),"\n",(0,s.jsx)(e.li,{children:"Completed the voice commands chapter for natural language understanding"}),"\n",(0,s.jsx)(e.li,{children:"Basic knowledge of Python and machine learning concepts"}),"\n",(0,s.jsx)(e.li,{children:"Understanding of robotic planning and navigation systems"}),"\n",(0,s.jsx)(e.li,{children:"Familiarity with API calls and external service integration"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"conceptual-overview",children:"Conceptual Overview"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Large Language Models (LLMs)"})," bring cognitive reasoning capabilities to robotics by enabling natural language understanding, task decomposition, and high-level planning. Unlike traditional symbolic planners, LLMs can interpret natural language instructions, reason about complex multi-step tasks, and adapt to novel situations."]}),"\n",(0,s.jsx)(e.h3,{id:"key-capabilities-of-llms-in-robotics",children:"Key Capabilities of LLMs in Robotics"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Natural Language Understanding"}),": Interpret human instructions in natural language"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Task Decomposition"}),": Break complex tasks into executable steps"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"World Modeling"}),": Understand spatial relationships and environmental constraints"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Commonsense Reasoning"}),": Apply general knowledge to novel situations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Adaptive Planning"}),": Modify plans based on changing conditions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Human-Robot Interaction"}),": Engage in natural dialogue about tasks and goals"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"llm-integration-architecture",children:"LLM Integration Architecture"}),"\n",(0,s.jsx)(e.p,{children:"The typical LLM integration architecture includes:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Natural Language \u2192 LLM \u2192 Task Plan \u2192 ROS Actions \u2192 Robot Execution\n"})}),"\n",(0,s.jsx)(e.p,{children:"With feedback loops for:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Execution monitoring and error handling"}),"\n",(0,s.jsx)(e.li,{children:"Plan refinement based on real-world observations"}),"\n",(0,s.jsx)(e.li,{children:"Natural language responses to human operators"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"advantages-of-llm-based-planning",children:"Advantages of LLM-Based Planning"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Natural Interaction"}),": Humans can specify tasks in everyday language"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Flexibility"}),": Handle novel tasks without pre-programming"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Reasoning"}),": Apply general knowledge to specific situations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Adaptability"}),": Adjust plans based on context and constraints"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Scalability"}),": Leverage pre-trained models without extensive training"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"hands-on-implementation",children:"Hands-On Implementation"}),"\n",(0,s.jsx)(e.h3,{id:"installing-llm-dependencies",children:"Installing LLM Dependencies"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Install LLM libraries\npip3 install openai anthropic transformers torch accelerate\npip3 install python-dotenv openai gymnasium numpy\n\n# For local models (optional)\npip3 install llama-cpp-python\n"})}),"\n",(0,s.jsx)(e.h3,{id:"creating-an-llm-planning-node",children:"Creating an LLM Planning Node"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\n"""\nLLM-based planning node for cognitive robotics.\n"""\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import PoseStamped\nfrom nav_msgs.msg import Path\nfrom action_msgs.msg import GoalStatus\nfrom rclpy.qos import QoSProfile, ReliabilityPolicy\nimport openai\nimport os\nimport json\nimport asyncio\nfrom typing import Dict, List, Optional\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass RobotCapability:\n    """Defines a robot\'s capabilities."""\n    name: str\n    description: str\n    parameters: Dict[str, str]\n\n\n@dataclass\nclass PlanningStep:\n    """Represents a single step in a plan."""\n    action: str\n    parameters: Dict[str, str]\n    description: str\n\n\nclass LLMPlanningNode(Node):\n    """\n    Node to use LLM for cognitive planning and task decomposition.\n    """\n\n    def __init__(self):\n        super().__init__(\'llm_planning_node\')\n\n        # Initialize OpenAI API (use your API key)\n        # For local models, use different approach\n        self.api_key = os.getenv(\'OPENAI_API_KEY\')\n        if self.api_key:\n            openai.api_key = self.api_key\n            self.use_remote_llm = True\n        else:\n            self.get_logger().warn(\'OPENAI_API_KEY not found, using mock responses\')\n            self.use_remote_llm = False\n\n        # Define robot capabilities\n        self.capabilities = [\n            RobotCapability(\n                name="move_to",\n                description="Move the robot to a specific location",\n                parameters={"x": "float", "y": "float", "theta": "float", "frame_id": "string"}\n            ),\n            RobotCapability(\n                name="pick_object",\n                description="Pick up an object at the current location",\n                parameters={"object_id": "string", "height": "float"}\n            ),\n            RobotCapability(\n                name="place_object",\n                description="Place an object at the current location",\n                parameters={"object_id": "string", "height": "float"}\n            ),\n            RobotCapability(\n                name="navigate_to",\n                description="Navigate to a named location in the environment",\n                parameters={"location_name": "string"}\n            ),\n            RobotCapability(\n                name="detect_object",\n                description="Detect and identify objects in the environment",\n                parameters={"object_type": "string", "range": "float"}\n            ),\n            RobotCapability(\n                name="follow_path",\n                description="Follow a predefined path",\n                parameters={"path_name": "string"}\n            ),\n            RobotCapability(\n                name="report_status",\n                description="Report the current status of the robot",\n                parameters={}\n            )\n        ]\n\n        # Create subscribers\n        self.task_sub = self.create_subscription(\n            String,\n            \'natural_language_task\',\n            self.task_callback,\n            10\n        )\n\n        # Create publishers\n        self.plan_pub = self.create_publisher(String, \'generated_plan\', 10)\n        self.response_pub = self.create_publisher(String, \'llm_response\', 10)\n\n        # Initialize variables\n        self.current_plan = []\n        self.task_history = []\n\n        self.get_logger().info(\'LLM planning node initialized\')\n\n    def task_callback(self, msg):\n        """Handle incoming natural language tasks."""\n        task_description = msg.data\n        self.get_logger().info(f\'Received task: {task_description}\')\n\n        # Generate plan using LLM\n        plan = self.generate_plan(task_description)\n\n        if plan:\n            # Publish the generated plan\n            plan_msg = String()\n            plan_msg.data = json.dumps(plan)\n            self.plan_pub.publish(plan_msg)\n\n            # Publish response\n            response_msg = String()\n            response_msg.data = f\'Generated plan with {len(plan)} steps for task: {task_description}\'\n            self.response_pub.publish(response_msg)\n\n            self.get_logger().info(f\'Published plan with {len(plan)} steps\')\n        else:\n            self.get_logger().error(\'Failed to generate plan\')\n\n    def generate_plan(self, task_description: str) -> Optional[List[Dict]]:\n        """Generate a plan for the given task using LLM."""\n        try:\n            # Create a prompt for the LLM\n            prompt = self.create_planning_prompt(task_description)\n\n            if self.use_remote_llm:\n                # Call OpenAI API\n                response = openai.ChatCompletion.create(\n                    model="gpt-3.5-turbo",\n                    messages=[\n                        {"role": "system", "content": self.get_system_prompt()},\n                        {"role": "user", "content": prompt}\n                    ],\n                    temperature=0.3,\n                    max_tokens=1000\n                )\n\n                plan_text = response.choices[0].message.content.strip()\n            else:\n                # Mock response for testing without API key\n                plan_text = self.mock_plan_generation(task_description)\n\n            # Parse the response\n            plan = self.parse_plan_response(plan_text)\n            return plan\n\n        except Exception as e:\n            self.get_logger().error(f\'Error generating plan: {e}\')\n            return None\n\n    def create_planning_prompt(self, task_description: str) -> str:\n        """Create a prompt for the LLM to generate a plan."""\n        capabilities_str = "\\n".join([\n            f"- {cap.name}: {cap.description} (params: {\', \'.join(cap.parameters.keys())})"\n            for cap in self.capabilities\n        ])\n\n        prompt = f"""\nYou are a helpful assistant that generates robot action plans from natural language descriptions.\nThe robot has the following capabilities:\n{capabilities_str}\n\nThe environment has known locations like: kitchen, bedroom, living room, office, charging_station.\n\nGiven the task: "{task_description}"\n\nGenerate a step-by-step plan using the available robot capabilities. Return only a JSON array of steps with the following format:\n[\n  {{\n    "action": "...",\n    "parameters": {{"param1": "value1", "param2": "value2"}},\n    "description": "..."\n  }}\n]\n\nBe specific about locations and objects. If you need to navigate to a named location, use "navigate_to". If you need to go to specific coordinates, use "move_to".\n"""\n\n        return prompt\n\n    def get_system_prompt(self) -> str:\n        """Get the system prompt for the LLM."""\n        return """\nYou are a helpful assistant that generates robot action plans from natural language descriptions.\nAlways respond with a valid JSON array of steps.\nEach step should have "action", "parameters", and "description" fields.\nOnly use the robot capabilities that are available.\nBe specific about locations and objects.\nIf information is missing, make reasonable assumptions based on common sense.\n"""\n\n    def parse_plan_response(self, response: str) -> Optional[List[Dict]]:\n        """Parse the LLM response into a structured plan."""\n        try:\n            # Try to extract JSON from the response\n            start_idx = response.find(\'[\')\n            end_idx = response.rfind(\']\') + 1\n\n            if start_idx != -1 and end_idx != 0:\n                json_str = response[start_idx:end_idx]\n                plan = json.loads(json_str)\n\n                # Validate the plan structure\n                for step in plan:\n                    if \'action\' not in step or \'parameters\' not in step or \'description\' not in step:\n                        raise ValueError("Invalid plan format")\n\n                return plan\n            else:\n                self.get_logger().error(f\'Could not find JSON in response: {response}\')\n                return None\n\n        except json.JSONDecodeError as e:\n            self.get_logger().error(f\'Error parsing JSON response: {e}\')\n            self.get_logger().info(f\'Response: {response}\')\n            return None\n        except Exception as e:\n            self.get_logger().error(f\'Error parsing plan response: {e}\')\n            return None\n\n    def mock_plan_generation(self, task_description: str) -> str:\n        """Generate a mock plan for testing without API key."""\n        # This is a simplified mock - in reality, you\'d want more sophisticated logic\n        if "kitchen" in task_description.lower():\n            return \'\'\'[\n  {\n    "action": "navigate_to",\n    "parameters": {"location_name": "kitchen"},\n    "description": "Navigate to the kitchen area"\n  },\n  {\n    "action": "report_status",\n    "parameters": {},\n    "description": "Report arrival at kitchen"\n  }\n]\'\'\'\n        elif "bedroom" in task_description.lower():\n            return \'\'\'[\n  {\n    "action": "navigate_to",\n    "parameters": {"location_name": "bedroom"},\n    "description": "Navigate to the bedroom area"\n  },\n  {\n    "action": "report_status",\n    "parameters": {},\n    "description": "Report arrival at bedroom"\n  }\n]\'\'\'\n        else:\n            return \'\'\'[\n  {\n    "action": "report_status",\n    "parameters": {},\n    "description": "Received task and ready to execute"\n  }\n]\'\'\'\n\n    def validate_plan(self, plan: List[Dict]) -> bool:\n        """Validate that the plan contains only valid actions."""\n        valid_actions = [cap.name for cap in self.capabilities]\n\n        for step in plan:\n            if step[\'action\'] not in valid_actions:\n                self.get_logger().error(f\'Invalid action in plan: {step["action"]}\')\n                return False\n\n        return True\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = LLMPlanningNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info(\'LLM planning node stopped by user\')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(e.h3,{id:"creating-a-plan-execution-node",children:"Creating a Plan Execution Node"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\n\n\"\"\"\nNode to execute plans generated by the LLM planning node.\n\"\"\"\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom nav_msgs.msg import Odometry\nfrom action_msgs.msg import GoalStatus\nimport json\nimport time\nfrom typing import Dict, Any\n\n\nclass PlanExecutionNode(Node):\n    \"\"\"\n    Node to execute plans generated by the LLM planning node.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('plan_execution_node')\n\n        # Create subscribers\n        self.plan_sub = self.create_subscription(\n            String,\n            'generated_plan',\n            self.plan_callback,\n            10\n        )\n\n        # Create publishers\n        self.cmd_vel_pub = self.create_publisher(Twist, 'cmd_vel', 10)\n        self.execution_status_pub = self.create_publisher(String, 'execution_status', 10)\n\n        # Subscribe to odometry for position feedback\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            'odom',\n            self.odom_callback,\n            10\n        )\n\n        # Initialize variables\n        self.current_odom = None\n        self.current_plan = []\n        self.current_step_index = 0\n        self.is_executing = False\n\n        self.get_logger().info('Plan execution node initialized')\n\n    def odom_callback(self, msg):\n        \"\"\"Update current robot position.\"\"\"\n        self.current_odom = msg\n\n    def plan_callback(self, msg):\n        \"\"\"Handle incoming plan.\"\"\"\n        try:\n            plan_data = json.loads(msg.data)\n            self.get_logger().info(f'Received plan with {len(plan_data)} steps')\n\n            # Store the plan and start execution\n            self.current_plan = plan_data\n            self.current_step_index = 0\n            self.is_executing = True\n\n            # Start executing the plan\n            self.execute_next_step()\n\n        except json.JSONDecodeError as e:\n            self.get_logger().error(f'Error decoding plan: {e}')\n        except Exception as e:\n            self.get_logger().error(f'Error processing plan: {e}')\n\n    def execute_next_step(self):\n        \"\"\"Execute the next step in the plan.\"\"\"\n        if not self.is_executing or self.current_step_index >= len(self.current_plan):\n            self.is_executing = False\n            self.publish_status('Plan completed')\n            return\n\n        step = self.current_plan[self.current_step_index]\n        self.get_logger().info(f'Executing step {self.current_step_index + 1}: {step[\"action\"]}')\n\n        # Execute based on action type\n        success = self.execute_action(step)\n\n        if success:\n            self.publish_status(f'Step completed: {step[\"description\"]}')\n            self.current_step_index += 1\n\n            # Schedule next step after a delay\n            self.create_timer(1.0, self.execute_next_step)\n        else:\n            self.publish_status(f'Step failed: {step[\"description\"]}')\n            self.is_executing = False\n\n    def execute_action(self, step: Dict[str, Any]) -> bool:\n        \"\"\"Execute a single action from the plan.\"\"\"\n        action = step['action']\n        parameters = step['parameters']\n\n        try:\n            if action == 'move_to':\n                return self.execute_move_to(parameters)\n            elif action == 'navigate_to':\n                return self.execute_navigate_to(parameters)\n            elif action == 'pick_object':\n                return self.execute_pick_object(parameters)\n            elif action == 'place_object':\n                return self.execute_place_object(parameters)\n            elif action == 'detect_object':\n                return self.execute_detect_object(parameters)\n            elif action == 'follow_path':\n                return self.execute_follow_path(parameters)\n            elif action == 'report_status':\n                return self.execute_report_status(parameters)\n            else:\n                self.get_logger().error(f'Unknown action: {action}')\n                return False\n\n        except Exception as e:\n            self.get_logger().error(f'Error executing action {action}: {e}')\n            return False\n\n    def execute_move_to(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute move_to action.\"\"\"\n        x = float(params.get('x', 0.0))\n        y = float(params.get('y', 0.0))\n        theta = float(params.get('theta', 0.0))\n\n        # Create and publish velocity command\n        twist = Twist()\n        twist.linear.x = 0.5  # Simple movement for demonstration\n        twist.angular.z = 0.2\n\n        # In a real implementation, this would interface with navigation stack\n        self.cmd_vel_pub.publish(twist)\n\n        self.get_logger().info(f'Moving to ({x}, {y}, {theta})')\n        time.sleep(2)  # Simulate movement time\n\n        # Stop the robot\n        stop_twist = Twist()\n        self.cmd_vel_pub.publish(stop_twist)\n\n        return True\n\n    def execute_navigate_to(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute navigate_to action.\"\"\"\n        location_name = params.get('location_name', '')\n\n        self.get_logger().info(f'Navigating to {location_name}')\n\n        # In a real implementation, this would send goals to navigation system\n        # For now, just simulate the action\n        time.sleep(3)  # Simulate navigation time\n\n        return True\n\n    def execute_pick_object(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute pick_object action.\"\"\"\n        object_id = params.get('object_id', '')\n        height = float(params.get('height', 0.5))\n\n        self.get_logger().info(f'Picking up object {object_id} at height {height}')\n\n        # Simulate picking action\n        time.sleep(2)\n\n        return True\n\n    def execute_place_object(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute place_object action.\"\"\"\n        object_id = params.get('object_id', '')\n        height = float(params.get('height', 0.5))\n\n        self.get_logger().info(f'Placing object {object_id} at height {height}')\n\n        # Simulate placing action\n        time.sleep(2)\n\n        return True\n\n    def execute_detect_object(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute detect_object action.\"\"\"\n        object_type = params.get('object_type', '')\n        range_val = float(params.get('range', 1.0))\n\n        self.get_logger().info(f'Detecting {object_type} within {range_val}m')\n\n        # Simulate detection\n        time.sleep(1)\n\n        return True\n\n    def execute_follow_path(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute follow_path action.\"\"\"\n        path_name = params.get('path_name', '')\n\n        self.get_logger().info(f'Following path {path_name}')\n\n        # Simulate path following\n        time.sleep(3)\n\n        return True\n\n    def execute_report_status(self, params: Dict[str, Any]) -> bool:\n        \"\"\"Execute report_status action.\"\"\"\n        self.get_logger().info('Reporting status')\n        return True\n\n    def publish_status(self, status: str):\n        \"\"\"Publish execution status.\"\"\"\n        status_msg = String()\n        status_msg.data = status\n        self.execution_status_pub.publish(status_msg)\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = PlanExecutionNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info('Plan execution node stopped by user')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(e.h3,{id:"creating-a-task-manager-node",children:"Creating a Task Manager Node"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\n\n\"\"\"\nTask manager node to coordinate LLM planning and execution.\n\"\"\"\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import PoseStamped\nimport json\nimport asyncio\nfrom typing import Dict, List, Optional\n\n\nclass TaskManagerNode(Node):\n    \"\"\"\n    Node to manage the overall task execution flow.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('task_manager_node')\n\n        # Create subscribers\n        self.voice_command_sub = self.create_subscription(\n            String,\n            'voice_commands',  # From voice command node\n            self.voice_command_callback,\n            10\n        )\n\n        self.execution_status_sub = self.create_subscription(\n            String,\n            'execution_status',\n            self.execution_status_callback,\n            10\n        )\n\n        # Create publishers\n        self.natural_task_pub = self.create_publisher(String, 'natural_language_task', 10)\n        self.system_status_pub = self.create_publisher(String, 'system_status', 10)\n\n        # Initialize variables\n        self.current_task = None\n        self.task_queue = []\n\n        self.get_logger().info('Task manager node initialized')\n\n    def voice_command_callback(self, msg):\n        \"\"\"Handle voice commands and convert to natural language tasks.\"\"\"\n        command = msg.data\n        self.get_logger().info(f'Received voice command: {command}')\n\n        # Convert voice command to natural language task\n        # In a real system, you might do more sophisticated NLP here\n        natural_task = self.convert_to_natural_task(command)\n\n        if natural_task:\n            # Publish the natural language task for LLM planning\n            task_msg = String()\n            task_msg.data = natural_task\n            self.natural_task_pub.publish(task_msg)\n\n            self.get_logger().info(f'Published natural task: {natural_task}')\n        else:\n            self.get_logger().warn(f'Could not convert command to natural task: {command}')\n\n    def convert_to_natural_task(self, command: str) -> Optional[str]:\n        \"\"\"Convert voice command to natural language task.\"\"\"\n        # This is a simplified conversion - in practice, you'd have more sophisticated NLP\n        command_lower = command.lower()\n\n        # Define common command patterns and their natural language equivalents\n        if 'move to' in command_lower or 'go to' in command_lower:\n            # Extract location if specified\n            if 'kitchen' in command_lower:\n                return 'Navigate to the kitchen and wait there'\n            elif 'bedroom' in command_lower:\n                return 'Go to the bedroom and report your arrival'\n            elif 'living room' in command_lower:\n                return 'Move to the living room'\n            else:\n                # Try to extract a general location\n                import re\n                location_match = re.search(r'(?:to|the)\\s+(\\w+)', command_lower)\n                if location_match:\n                    location = location_match.group(1)\n                    return f'Go to the {location} area'\n\n        elif 'pick' in command_lower or 'grasp' in command_lower:\n            # Extract object if specified\n            import re\n            object_match = re.search(r'(?:pick|grasp|take)\\s+(?:up\\s+)?(\\w+)', command_lower)\n            if object_match:\n                obj = object_match.group(1)\n                return f'Pick up the {obj} from the current location'\n\n        elif 'place' in command_lower or 'put' in command_lower:\n            # Extract object if specified\n            import re\n            object_match = re.search(r'(?:place|put)\\s+(?:down\\s+)?(\\w+)', command_lower)\n            if object_match:\n                obj = object_match.group(1)\n                return f'Put down the {obj} at the current location'\n\n        elif 'stop' in command_lower or 'halt' in command_lower:\n            return 'Stop all current activities and remain in place'\n\n        elif 'status' in command_lower or 'where' in command_lower:\n            return 'Report your current status and location'\n\n        # If no specific pattern matched, use the command as-is with some context\n        if len(command) > 3:  # At least 3 characters\n            return f'{command.capitalize()}. Perform this task using your available capabilities.'\n\n        return None\n\n    def execution_status_callback(self, msg):\n        \"\"\"Handle execution status updates.\"\"\"\n        status = msg.data\n        self.get_logger().info(f'Execution status: {status}')\n\n        # Publish system status\n        system_status = String()\n        system_status.data = f'LLM Planning System: {status}'\n        self.system_status_pub.publish(system_status)\n\n        # Check if we have more tasks to process\n        if self.task_queue and status.startswith('Plan completed'):\n            next_task = self.task_queue.pop(0)\n            task_msg = String()\n            task_msg.data = next_task\n            self.natural_task_pub.publish(task_msg)\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = TaskManagerNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info('Task manager node stopped by user')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(e.h3,{id:"creating-a-local-llm-integration-alternative-to-api-based",children:"Creating a Local LLM Integration (Alternative to API-based)"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\n"""\nLocal LLM integration using transformers library.\nThis provides an alternative to API-based LLMs for privacy or offline use.\n"""\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nimport json\nimport os\nfrom typing import Dict, List, Optional\n\n\nclass LocalLLMNode(Node):\n    """\n    Node to use local LLM for planning (privacy-preserving alternative).\n    """\n\n    def __init__(self):\n        super().__init__(\'local_llm_node\')\n\n        # Initialize local model (using a smaller, faster model for demonstration)\n        # For production, you might use models like Phi-3, TinyLlama, or others\n        try:\n            model_name = "microsoft/DialoGPT-small"  # Example - replace with appropriate model\n\n            # For this example, we\'ll use a mock approach since actual model loading\n            # might be resource-intensive for the documentation example\n            self.use_local_model = False\n            self.get_logger().info(\'Local LLM node initialized (mock mode)\')\n\n        except Exception as e:\n            self.get_logger().warn(f\'Could not load local model: {e}\')\n            self.use_local_model = False\n\n        # Create subscribers\n        self.task_sub = self.create_subscription(\n            String,\n            \'natural_language_task\',\n            self.task_callback,\n            10\n        )\n\n        # Create publishers\n        self.plan_pub = self.create_publisher(String, \'generated_plan\', 10)\n        self.response_pub = self.create_publisher(String, \'llm_response\', 10)\n\n        self.get_logger().info(\'Local LLM planning node initialized\')\n\n    def task_callback(self, msg):\n        """Handle incoming natural language tasks."""\n        task_description = msg.data\n        self.get_logger().info(f\'Received task (local): {task_description}\')\n\n        # Generate plan using local processing or mock\n        plan = self.generate_plan_local(task_description)\n\n        if plan:\n            # Publish the generated plan\n            plan_msg = String()\n            plan_msg.data = json.dumps(plan)\n            self.plan_pub.publish(plan_msg)\n\n            # Publish response\n            response_msg = String()\n            response_msg.data = f\'Generated plan with {len(plan)} steps for task: {task_description}\'\n            self.response_pub.publish(response_msg)\n\n            self.get_logger().info(f\'Published plan with {len(plan)} steps\')\n        else:\n            self.get_logger().error(\'Failed to generate plan locally\')\n\n    def generate_plan_local(self, task_description: str) -> Optional[List[Dict]]:\n        """Generate a plan locally (mock implementation)."""\n        # In a real implementation, you would use a local LLM\n        # For this example, we\'ll use rule-based generation with some ML concepts\n\n        # Define a simple rule-based planner for demonstration\n        task_lower = task_description.lower()\n\n        plan = []\n\n        # Rule-based planning logic\n        if \'kitchen\' in task_lower:\n            plan.extend([\n                {\n                    "action": "navigate_to",\n                    "parameters": {"location_name": "kitchen"},\n                    "description": "Navigate to the kitchen area"\n                },\n                {\n                    "action": "report_status",\n                    "parameters": {},\n                    "description": "Report arrival at kitchen"\n                }\n            ])\n        elif \'bedroom\' in task_lower:\n            plan.extend([\n                {\n                    "action": "navigate_to",\n                    "parameters": {"location_name": "bedroom"},\n                    "description": "Navigate to the bedroom area"\n                },\n                {\n                    "action": "report_status",\n                    "parameters": {},\n                    "description": "Report arrival at bedroom"\n                }\n            ])\n        elif \'pick\' in task_lower or \'grasp\' in task_lower:\n            # Extract object name if possible\n            import re\n            obj_match = re.search(r\'(?:pick|grasp|take)\\s+(?:up\\s+)?(\\w+)\', task_lower)\n            obj_name = obj_match.group(1) if obj_match else "object"\n\n            plan.extend([\n                {\n                    "action": "detect_object",\n                    "parameters": {"object_type": obj_name, "range": 1.0},\n                    "description": f"Detect the {obj_name} in the environment"\n                },\n                {\n                    "action": "pick_object",\n                    "parameters": {"object_id": obj_name, "height": 0.5},\n                    "description": f"Pick up the {obj_name}"\n                }\n            ])\n        else:\n            # Default action for unrecognized tasks\n            plan.append({\n                "action": "report_status",\n                "parameters": {},\n                "description": f"Received task: {task_description}"\n            })\n\n        return plan\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = LocalLLMNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info(\'Local LLM node stopped by user\')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(e.h3,{id:"creating-a-safety-and-validation-node",children:"Creating a Safety and Validation Node"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\n\n\"\"\"\nSafety and validation node for LLM-generated plans.\n\"\"\"\n\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Pose, Point\nfrom sensor_msgs.msg import LaserScan\nfrom nav_msgs.msg import OccupancyGrid\nimport json\nfrom typing import Dict, List, Optional\n\n\nclass SafetyValidatorNode(Node):\n    \"\"\"\n    Node to validate LLM-generated plans for safety and feasibility.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__('safety_validator_node')\n\n        # Create subscribers\n        self.plan_sub = self.create_subscription(\n            String,\n            'generated_plan',\n            self.plan_callback,\n            10\n        )\n\n        self.laser_sub = self.create_subscription(\n            LaserScan,\n            '/scan',\n            self.laser_callback,\n            10\n        )\n\n        self.map_sub = self.create_subscription(\n            OccupancyGrid,\n            '/map',\n            self.map_callback,\n            10\n        )\n\n        # Create publishers\n        self.validated_plan_pub = self.create_publisher(String, 'validated_plan', 10)\n        self.safety_alert_pub = self.create_publisher(String, 'safety_alerts', 10)\n\n        # Initialize variables\n        self.laser_data = None\n        self.map_data = None\n        self.map_metadata = None\n\n        self.get_logger().info('Safety validator node initialized')\n\n    def plan_callback(self, msg):\n        \"\"\"Validate incoming plan.\"\"\"\n        try:\n            plan = json.loads(msg.data)\n            self.get_logger().info(f'Validating plan with {len(plan)} steps')\n\n            # Validate the plan\n            is_safe, validated_plan, alerts = self.validate_plan(plan)\n\n            if is_safe:\n                # Publish validated plan\n                validated_msg = String()\n                validated_msg.data = json.dumps(validated_plan)\n                self.validated_plan_pub.publish(validated_msg)\n\n                self.get_logger().info('Plan validated and published')\n            else:\n                # Publish safety alerts\n                for alert in alerts:\n                    alert_msg = String()\n                    alert_msg.data = alert\n                    self.safety_alert_pub.publish(alert_msg)\n\n                self.get_logger().warn(f'Plan rejected with {len(alerts)} safety issues')\n\n        except json.JSONDecodeError as e:\n            self.get_logger().error(f'Error decoding plan: {e}')\n        except Exception as e:\n            self.get_logger().error(f'Error validating plan: {e}')\n\n    def validate_plan(self, plan: List[Dict]) -> tuple:\n        \"\"\"Validate plan for safety and feasibility.\"\"\"\n        alerts = []\n        validated_plan = []\n\n        for i, step in enumerate(plan):\n            action = step['action']\n            params = step['parameters']\n\n            # Validate based on action type\n            if action == 'move_to':\n                is_valid, alert = self.validate_move_to(params)\n                if not is_valid:\n                    alerts.append(f'Step {i}: {alert}')\n                    continue  # Skip invalid step\n            elif action == 'navigate_to':\n                is_valid, alert = self.validate_navigate_to(params)\n                if not is_valid:\n                    alerts.append(f'Step {i}: {alert}')\n                    continue  # Skip invalid step\n\n            # Add valid step to validated plan\n            validated_plan.append(step)\n\n        is_safe = len(alerts) == 0\n        return is_safe, validated_plan, alerts\n\n    def validate_move_to(self, params: Dict) -> tuple:\n        \"\"\"Validate move_to action for safety.\"\"\"\n        try:\n            x = float(params.get('x', 0.0))\n            y = float(params.get('y', 0.0))\n\n            # Check if coordinates are within reasonable bounds\n            if abs(x) > 100 or abs(y) > 100:\n                return False, f'Coordinates ({x}, {y}) exceed safe operational bounds'\n\n            # Check if destination is in known map (if map is available)\n            if self.map_data and self.map_metadata:\n                if not self.is_location_traversable(x, y):\n                    return False, f'Destination ({x}, {y}) is not traversable'\n\n            # Check for immediate obstacles (using laser data if available)\n            if self.laser_data:\n                if self.has_immediate_obstacles(x, y):\n                    return False, f'Immediate obstacles detected near destination ({x}, {y})'\n\n            return True, \"\"\n\n        except (ValueError, TypeError) as e:\n            return False, f'Invalid coordinates in parameters: {e}'\n\n    def validate_navigate_to(self, params: Dict) -> tuple:\n        \"\"\"Validate navigate_to action for safety.\"\"\"\n        location_name = params.get('location_name', '').lower()\n\n        # Check if location name is valid\n        valid_locations = ['kitchen', 'bedroom', 'living room', 'office', 'charging_station']\n        if location_name not in valid_locations:\n            # For this example, we'll accept any location name\n            # In a real system, you'd validate against known locations\n            pass\n\n        # Additional validation can be added based on map data\n        if self.map_data and self.map_metadata:\n            if not self.is_known_location(location_name):\n                return False, f'Location \"{location_name}\" is not in known map'\n\n        return True, \"\"\n\n    def is_location_traversable(self, x: float, y: float) -> bool:\n        \"\"\"Check if a location is traversable based on map data.\"\"\"\n        if not self.map_data or not self.map_metadata:\n            return True  # Assume traversable if no map data\n\n        try:\n            # Convert world coordinates to map coordinates\n            origin_x = self.map_metadata.origin.position.x\n            origin_y = self.map_metadata.origin.position.y\n            resolution = self.map_metadata.resolution\n\n            map_x = int((x - origin_x) / resolution)\n            map_y = int((y - origin_y) / resolution)\n\n            # Check bounds\n            if (map_x < 0 or map_x >= self.map_metadata.width or\n                map_y < 0 or map_y >= self.map_metadata.height):\n                return False\n\n            # Check occupancy value (0 = free, 100 = occupied)\n            idx = map_y * self.map_metadata.width + map_x\n            if idx < len(self.map_data.data):\n                occupancy = self.map_data.data[idx]\n                return occupancy < 50  # Consider <50 as traversable\n\n        except Exception as e:\n            self.get_logger().warn(f'Error checking traversability: {e}')\n\n        return True\n\n    def has_immediate_obstacles(self, x: float, y: float) -> bool:\n        \"\"\"Check if there are immediate obstacles near destination.\"\"\"\n        if not self.laser_data:\n            return False\n\n        # This is a simplified check - in practice, you'd do more sophisticated analysis\n        # Check if any laser readings indicate close obstacles\n        min_distance = min(self.laser_data.ranges) if self.laser_data.ranges else float('inf')\n        return min_distance < 0.5  # Consider <0.5m as immediate obstacle\n\n    def is_known_location(self, location_name: str) -> bool:\n        \"\"\"Check if location is known in the map.\"\"\"\n        # In a real implementation, this would check against semantic map\n        # For this example, we'll return True to avoid blocking execution\n        return True\n\n    def laser_callback(self, msg):\n        \"\"\"Update laser data.\"\"\"\n        self.laser_data = msg\n\n    def map_callback(self, msg):\n        \"\"\"Update map data.\"\"\"\n        self.map_data = msg.data\n        self.map_metadata = msg.info\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = SafetyValidatorNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info('Safety validator node stopped by user')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(e.h3,{id:"creating-a-complete-llm-planning-package",children:"Creating a Complete LLM Planning Package"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Create the package:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"cd ~/ros2_ws/src\nros2 pkg create --build-type ament_python llm_planning\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Update package.xml:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>\n<package format="3">\n  <name>llm_planning</name>\n  <version>0.0.1</version>\n  <description>LLM-based planning for robotics</description>\n  <maintainer email="user@todo.todo">user</maintainer>\n  <license>Apache-2.0</license>\n\n  <depend>rclpy</depend>\n  <depend>std_msgs</depend>\n  <depend>geometry_msgs</depend>\n  <depend>nav_msgs</depend>\n  <depend>sensor_msgs</depend>\n\n  <export>\n    <build_type>ament_python</build_type>\n  </export>\n</package>\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Create setup.py:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"from setuptools import find_packages, setup\n\npackage_name = 'llm_planning'\n\nsetup(\n    name=package_name,\n    version='0.0.1',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n    ],\n    install_requires=['setuptools'],\n    zip_safe=True,\n    maintainer='user',\n    maintainer_email='user@todo.todo',\n    description='LLM-based planning for robotics',\n    license='Apache-2.0',\n    tests_require=['pytest'],\n    entry_points={\n        'console_scripts': [\n            'llm_planning_node = llm_planning.llm_planning_node:main',\n            'plan_execution_node = llm_planning.plan_execution_node:main',\n            'task_manager_node = llm_planning.task_manager_node:main',\n            'local_llm_node = llm_planning.local_llm_node:main',\n            'safety_validator_node = llm_planning.safety_validator_node:main',\n        ],\n    },\n)\n"})}),"\n",(0,s.jsx)(e.h3,{id:"creating-a-launch-file",children:"Creating a Launch File"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Create launch/llm_planning_launch.py:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.substitutions import LaunchConfiguration\nfrom launch_ros.actions import Node\n\n\ndef generate_launch_description():\n    # Declare launch arguments\n    use_sim_time = DeclareLaunchArgument(\n        'use_sim_time',\n        default_value='false',\n        description='Use simulation time if true'\n    )\n\n    # LLM planning node\n    llm_planning_node = Node(\n        package='llm_planning',\n        executable='llm_planning_node',\n        name='llm_planning_node',\n        parameters=[\n            {'use_sim_time': LaunchConfiguration('use_sim_time')}\n        ],\n        output='screen'\n    )\n\n    # Plan execution node\n    plan_execution_node = Node(\n        package='llm_planning',\n        executable='plan_execution_node',\n        name='plan_execution_node',\n        parameters=[\n            {'use_sim_time': LaunchConfiguration('use_sim_time')}\n        ],\n        output='screen'\n    )\n\n    # Task manager node\n    task_manager_node = Node(\n        package='llm_planning',\n        executable='task_manager_node',\n        name='task_manager_node',\n        parameters=[\n            {'use_sim_time': LaunchConfiguration('use_sim_time')}\n        ],\n        output='screen'\n    )\n\n    # Safety validator node\n    safety_validator_node = Node(\n        package='llm_planning',\n        executable='safety_validator_node',\n        name='safety_validator_node',\n        parameters=[\n            {'use_sim_time': LaunchConfiguration('use_sim_time')}\n        ],\n        output='screen'\n    )\n\n    return LaunchDescription([\n        use_sim_time,\n        llm_planning_node,\n        plan_execution_node,\n        task_manager_node,\n        safety_validator_node\n    ])\n"})}),"\n",(0,s.jsx)(e.h2,{id:"testing--verification",children:"Testing & Verification"}),"\n",(0,s.jsx)(e.h3,{id:"running-llm-planning-system",children:"Running LLM Planning System"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.strong,{children:"Set up your OpenAI API key (optional):"})}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'# Create a .env file or export the key\nexport OPENAI_API_KEY="your-api-key-here"\n'})}),"\n",(0,s.jsxs)(e.ol,{start:"2",children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.strong,{children:"Install dependencies:"})}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"pip3 install openai anthropic transformers torch\n"})}),"\n",(0,s.jsxs)(e.ol,{start:"3",children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.strong,{children:"Build the package:"})}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"cd ~/ros2_ws\ncolcon build --packages-select llm_planning\nsource install/setup.bash\n"})}),"\n",(0,s.jsxs)(e.ol,{start:"4",children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.strong,{children:"Run the LLM planning system:"})}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Terminal 1: Launch the system\nros2 launch llm_planning llm_planning_launch.py\n\n# Terminal 2: Send a test task\nros2 topic pub /natural_language_task std_msgs/msg/String \"data: 'Go to the kitchen and wait there'\"\n"})}),"\n",(0,s.jsxs)(e.ol,{start:"5",children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.strong,{children:"Monitor the planning process:"})}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Check generated plans\nros2 topic echo /generated_plan\n\n# Check execution status\nros2 topic echo /execution_status\n\n# Check safety alerts\nros2 topic echo /safety_alerts\n"})}),"\n",(0,s.jsx)(e.h3,{id:"useful-llm-planning-commands",children:"Useful LLM Planning Commands"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.strong,{children:"Test with voice commands:"})}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# If you have the voice command system running\nros2 topic pub /voice_commands std_msgs/msg/String \"data: 'move to kitchen'\"\n"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.strong,{children:"Monitor plan validation:"})}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"ros2 topic echo /validated_plan\n"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.strong,{children:"Check system status:"})}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"ros2 topic echo /system_status\n"})}),"\n",(0,s.jsx)(e.h3,{id:"performance-testing",children:"Performance Testing"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Test response times for different types of commands\n# Test with various levels of task complexity\n# Test safety validation effectiveness\n# Test integration with navigation system\n"})}),"\n",(0,s.jsx)(e.h2,{id:"common-issues",children:"Common Issues"}),"\n",(0,s.jsx)(e.h3,{id:"issue-api-rate-limits-or-costs-with-remote-llms",children:"Issue: API rate limits or costs with remote LLMs"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Solution"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Implement local models for frequently-used tasks"}),"\n",(0,s.jsx)(e.li,{children:"Use caching for repeated requests"}),"\n",(0,s.jsx)(e.li,{children:"Implement request queuing to respect rate limits"}),"\n",(0,s.jsx)(e.li,{children:"Consider hybrid approach with local models for simple tasks"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"issue-hallucinations-or-incorrect-plans-from-llm",children:"Issue: Hallucinations or incorrect plans from LLM"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Solution"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Implement safety validation layers"}),"\n",(0,s.jsx)(e.li,{children:"Use structured output formats (JSON)"}),"\n",(0,s.jsx)(e.li,{children:"Add domain-specific constraints"}),"\n",(0,s.jsx)(e.li,{children:"Implement plan verification before execution"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"issue-latency-in-plan-generation",children:"Issue: Latency in plan generation"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Solution"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Use smaller, faster models for real-time applications"}),"\n",(0,s.jsx)(e.li,{children:"Implement plan caching for common tasks"}),"\n",(0,s.jsx)(e.li,{children:"Use local inference where possible"}),"\n",(0,s.jsx)(e.li,{children:"Implement asynchronous processing"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"issue-safety-and-validation-challenges",children:"Issue: Safety and validation challenges"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Solution"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Implement multiple validation layers"}),"\n",(0,s.jsx)(e.li,{children:"Use formal methods for critical safety checks"}),"\n",(0,s.jsx)(e.li,{children:"Implement human-in-the-loop for high-risk actions"}),"\n",(0,s.jsx)(e.li,{children:"Maintain conservative safety margins"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"LLMs enable natural language task specification for robots"}),"\n",(0,s.jsx)(e.li,{children:"Safety validation is crucial for LLM-generated plans"}),"\n",(0,s.jsx)(e.li,{children:"Local models provide privacy and reliability benefits"}),"\n",(0,s.jsx)(e.li,{children:"Integration with existing ROS systems requires careful architecture"}),"\n",(0,s.jsx)(e.li,{children:"Hybrid approaches combine LLM flexibility with traditional planning"}),"\n",(0,s.jsx)(e.li,{children:"Human-robot collaboration is enhanced through cognitive planning"}),"\n",(0,s.jsx)(e.li,{children:"Proper error handling and fallback mechanisms are essential"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(e.p,{children:"In the next chapter, you'll learn about integrating voice commands with LLM planning to create a complete Vision-Language-Action system."})]})}function d(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(p,{...n})}):p(n)}},7074:(n,e,a)=>{a.d(e,{R:()=>l,x:()=>o});var t=a(6540);const s={},i=t.createContext(s);function l(n){const e=t.useContext(i);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:l(n.components),t.createElement(i.Provider,{value:e},n.children)}}}]);